Lookback using:  10
Using as train set: ../classification/dataset_10_lookback/x_real_dataset_train_4072_users_extendend_features.npy
Using as test set: ../classification/dataset_10_lookback/x_real_dataset_test_4072_users_extendend_features.npy
Fitting 3 folds for each of 135 candidates, totalling 405 fits
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
2020-02-14 19:00:59.999306: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:00:59.999813: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5050de0 executing computations on platform Host. Devices:
2020-02-14 19:00:59.999840: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.017775: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.018360: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5f2df80 executing computations on platform Host. Devices:
2020-02-14 19:01:00.018381: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.029315: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.029839: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x609f300 executing computations on platform Host. Devices:
2020-02-14 19:01:00.029862: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.034751: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.035273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4fffcd0 executing computations on platform Host. Devices:
2020-02-14 19:01:00.035295: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.052630: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.053154: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5298cd0 executing computations on platform Host. Devices:
2020-02-14 19:01:00.053174: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.059544: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-14 19:01:00.064604: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.065077: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cfaf30 executing computations on platform Host. Devices:
2020-02-14 19:01:00.065097: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.076799: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-14 19:01:00.089840: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-14 19:01:00.096260: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-14 19:01:00.096720: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.097100: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x52ba690 executing computations on platform Host. Devices:
2020-02-14 19:01:00.097121: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-14 19:01:00.113474: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-14 19:01:00.126523: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-14 19:01:00.137312: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-14 19:01:00.137717: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x65799c0 executing computations on platform Host. Devices:
2020-02-14 19:01:00.137738: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-14 19:01:00.156173: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-14 19:01:00.196485: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.944, total= 5.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.902, total=10.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.963, total=15.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.974, total=26.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.817, total=28.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.945, total=31.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.956, total=54.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.661, total=57.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.975, total=11.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.673, total=11.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.981, total=34.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.983, total=12.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.782, total=12.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=34.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.796, total=85.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.962, total=170.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=12.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=35.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.500, total=29.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=30.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=34.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.935, total=173.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.993, total=53.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.919, total=14.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.723, total=30.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.984, total=15.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=52.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.964, total=31.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.453, total= 3.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.513, total= 3.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.958, total= 6.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.703, total= 6.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.980, total=21.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 6.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 6.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.6min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.965, total=10.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=32.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.754, total=80.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.748, total=54.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=171.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.903, total=29.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=83.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.903, total=58.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=174.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=85.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=58.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.975, total= 2.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.983, total= 3.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.769, total= 3.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.976, total= 6.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.974, total= 6.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.812, total= 6.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.964, total=21.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.984, total= 6.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.915, total= 6.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.821, total= 6.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=22.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.968, total= 7.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.955, total=15.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.952, total=16.1min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.819, total=15.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.986, total=14.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.968, total=30.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.866, total=31.3min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.969, total= 3.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.703, total= 3.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.978, total= 6.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.976, total=21.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.786, total=21.3min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.959, total=52.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.731, total=30.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=105.9min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.977, total=31.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.764, total=14.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.976, total=27.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=82.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.954, total=57.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.975, total= 6.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.979, total= 6.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.772, total= 6.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.971, total=11.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.974, total=35.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.780, total=36.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.891, total=16.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.963, total=28.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.973, total=30.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.922, total=33.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.628, total=33.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.740, total=168.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total=17.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total=17.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.679, total=84.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.500, total=58.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=177.1min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=53.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.818, total=30.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.976, total= 3.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.977, total= 6.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.752, total= 6.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.987, total=21.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.673, total= 6.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.795, total= 6.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.680, total= 6.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.976, total= 7.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.774, total= 7.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.967, total=15.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.780, total=15.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.965, total=15.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.925, total=30.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.943, total=31.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.2min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.975, total=32.4min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.953, total=26.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=82.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.831, total=170.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.969, total=15.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.837, total=15.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.972, total=83.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.977, total=55.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.809, total=57.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.927, total=11.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.523, total=12.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.982, total=36.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=12.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=12.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=34.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.978, total=84.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.910, total=57.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=61.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.976, total=21.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.778, total=21.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=22.1min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.976, total= 7.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.768, total= 7.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.975, total=53.1min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.771, total=14.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.981, total=104.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.985, total=52.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.918, total=31.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=105.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.761, total=52.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.966, total=104.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.976, total=45.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.974, total=26.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.907, total=27.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.930, total= 2.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.971, total= 5.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.852, total= 5.6min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.854, total= 5.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.979, total=10.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=32.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.887, total=27.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.966, total=31.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.688, total=30.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.922, total=169.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=35.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.961, total=84.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.713, total=56.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=175.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=29.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=86.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=59.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=174.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.931, total=104.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.783, total=15.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=52.7min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.733, total=105.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 7.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.944, total=15.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=15.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=54.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=31.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.980, total= 2.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.975, total= 5.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.763, total= 5.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.625, total=18.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.964, total= 5.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.973, total= 5.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.739, total= 5.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.976, total= 5.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.972, total= 5.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.972, total=13.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.803, total=45.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.958, total=91.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.981, total=10.4min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.700, total=11.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.964, total=15.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.759, total=26.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=83.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.927, total=56.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=174.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=85.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.965, total=58.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.500, total= 6.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.500, total= 6.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.500, total= 6.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.500, total=12.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.781, total=35.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.804, total=35.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=35.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.977, total=86.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.739, total=58.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=172.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=53.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.888, total=30.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=105.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=53.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.672, total=31.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.496, total= 3.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.821, total= 6.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.971, total=21.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.745, total=21.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.987, total=52.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.710, total=30.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.743, total=91.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.967, total= 5.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.976, total=13.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.522, total=14.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.823, total=10.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=32.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.902, total=80.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.977, total=168.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=11.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=34.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.955, total=28.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.796, total=29.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.901, total=32.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.865, total=56.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=171.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.507, total=28.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=84.7min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.799, total=168.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.808, total=15.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.977, total=15.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=53.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.857, total=104.3min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.962, total= 7.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.977, total=15.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.933, total=15.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.914, total=14.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.746, total=14.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.961, total=103.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=21.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.650, total=15.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=52.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.731, total=104.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.786, total= 5.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.780, total=13.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.975, total=13.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=45.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.969, total=26.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=91.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.953, total=11.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.972, total=26.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.945, total=26.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.977, total= 5.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.711, total=31.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.983, total=81.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.851, total=54.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=171.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.703, total=28.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=84.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.884, total=171.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total=16.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.975, total=28.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=29.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=32.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=32.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.935, total=170.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.945, total=15.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.800, total=52.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.957, total=30.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=105.7min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.775, total=52.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.980, total=104.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 6.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 7.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 7.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.500, total=15.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=15.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=14.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=14.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.955, total=104.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.972, total=45.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.962, total=26.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=91.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.974, total=45.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.756, total=26.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=91.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=13.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=27.4min

[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=92.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=27.2min

[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.975, total=52.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.733, total=31.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.875, total=14.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.890, total=27.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.869, total= 2.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.540, total= 2.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.977, total= 5.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.973, total=18.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.755, total=18.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.983, total= 6.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.751, total= 6.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.974, total=13.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.799, total=13.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.975, total=11.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.830, total=11.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.967, total=90.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 5.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 6.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 6.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.826, total=13.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=13.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=11.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=12.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.974, total=89.9min

[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.976, total=45.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.964, total=27.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=92.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.750, total=45.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.974, total=90.3min

[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=15.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.973, total=31.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=32.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.961, total=11.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.727, total=27.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=91.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.681, total=14.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.959, total=27.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.519, total= 2.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.654, total= 2.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.651, total= 5.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.538, total= 5.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.958, total=18.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 5.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total= 5.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.515, total=13.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.729, total=90.1min

[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.868, total=27.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.498, total= 2.5min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.757, total= 5.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.953, total=18.5min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.721, total=18.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.975, total=45.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.550, total=27.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=91.3min

[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=16.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=53.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=32.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.972, total= 2.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.782, total= 2.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.984, total= 5.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.974, total=18.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.791, total=18.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=19.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.962, total=14.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.984, total=14.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.984, total=11.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.747, total=11.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.985, total=91.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.660, total= 6.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=19.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.761, total=46.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.962, total=92.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=19.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.964, total=45.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.716, total=27.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=90.7min
2020-02-16 04:26:41.182978: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-16 04:26:41.184480: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4df57f0 executing computations on platform Host. Devices:
2020-02-16 04:26:41.184587: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-16 04:26:41.276156: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 43.4min
[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 694.3min
[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 1465.7min
[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 2005.7min finished
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.


[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.978, total=18.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.966, total= 5.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.793, total= 5.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=18.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.734, total=13.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=46.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.771, total=91.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.500, total= 5.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.846, total=13.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=14.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.500, total=11.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.770, total=27.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.500, total=27.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=90.5min
Best: 0.944842 using {'batch_size': 128, 'dropout_rate': 0.2, 'epochs': 25, 'layers': {'input': 128, 'hidden1': 64, 'output': 1}}
Confusion Matrix:
34840.12 5583.88
4.87 103.13
f1:  0.040658398488557124
balanced accuracy:  0.9083873075034264
precision:  0.02081963940790892
recall (tpr):  0.9549074074074079
fpr:  0.13813279240055412
aucpr:  0.487923599397
Roc_auc score: 0.9083873075034264
