Lookback using:  10
Using as train set: ../classification/dataset_10_lookback/x_train_4072_users_ALL_scenario_extendend_features.npy
Using as test set: ../classification/dataset_10_lookback/x_test_4072_users_ALL_scenario_extendend_features.npy
Fitting 3 folds for each of 135 candidates, totalling 405 fits
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.
2020-02-17 14:00:40.501846: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.502896: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5269650 executing computations on platform Host. Devices:
2020-02-17 14:00:40.502931: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.531087: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.531794: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e14340 executing computations on platform Host. Devices:
2020-02-17 14:00:40.531817: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.532274: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.532841: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5e68b90 executing computations on platform Host. Devices:
2020-02-17 14:00:40.532870: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.538201: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.539152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x486ae90 executing computations on platform Host. Devices:
2020-02-17 14:00:40.539175: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.557801: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.558690: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5056490 executing computations on platform Host. Devices:
2020-02-17 14:00:40.558718: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.578545: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-17 14:00:40.605813: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.606521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5cecdf0 executing computations on platform Host. Devices:
2020-02-17 14:00:40.606544: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-17 14:00:40.608985: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-17 14:00:40.611619: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-17 14:00:40.615182: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-17 14:00:40.635484: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
2020-02-17 14:00:40.641729: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.642504: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48a01e0 executing computations on platform Host. Devices:
2020-02-17 14:00:40.642526: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-17 14:00:40.677180: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-17 14:00:40.681229: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-17 14:00:40.682031: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x48132a0 executing computations on platform Host. Devices:
2020-02-17 14:00:40.682059: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-17 14:00:40.725098: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

2020-02-17 14:00:40.764969: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Using TensorFlow backend.
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
WARNING:tensorflow:Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=32.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=144.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=93.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=304.4min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=149.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total=13.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total=14.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=25.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=24.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=72.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=24.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=25.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total=32.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total=32.2min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=107.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=63.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=189.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=105.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.997, total=69.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=234.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=62.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=33.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 3.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=26.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=19.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 7.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 8.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total= 8.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=16.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=17.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=16.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=16.3min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=114.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=23.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=57.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=127.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=1.000, total=96.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.997, total=98.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=104.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=173.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.997, total=139.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total=14.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total=25.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=72.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=74.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total=32.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=58.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=35.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=94.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=64.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 7.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 7.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=13.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=13.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=39.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=13.7min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=38.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=33.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.996, total=35.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=39.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=67.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=234.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=62.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=33.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.998, total=141.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.997, total=58.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=34.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=23.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=23.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=23.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=57.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total=15.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=36.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=142.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=96.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=108.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=90.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.997, total=417.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=78.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=49.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=93.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.997, total=190.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=18.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=32.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=35.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=37.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=36.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.994, total=225.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=24.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=19.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=18.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=16.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=15.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=139.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=23.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=16.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=17.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=15.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=33.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=34.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.996, total=116.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=16.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=33.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=34.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 2.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.6min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.2min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.998, total=129.0min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=94.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=298.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.991, total=398.5min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.996, total=73.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=105.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=59.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.994, total=62.7min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 7.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total=12.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=37.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=38.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total=17.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=18.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.996, total=103.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.998, total=221.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=34.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=69.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=15.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=139.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=23.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=16.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=57.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.995, total=114.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total= 7.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=16.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=17.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.998, total=57.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.996, total=34.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=20.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total= 6.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=14.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total=32.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=142.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.996, total=295.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=417.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=24.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=73.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=49.1min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.998, total=31.9min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.998, total=34.6min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.996, total=60.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=188.1min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=102.6min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=67.3min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.993, total=69.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 8.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=29.5min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 8.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=10.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 9.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=28.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=11.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=1.000, total=24.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=68.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=33.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=141.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=57.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=113.8min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 7.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 8.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 8.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.998, total=16.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=17.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=16.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=16.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=113.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=14.7min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=49.4min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total=15.6min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=137.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=301.8min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=170.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=373.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=104.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=187.7min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=13.2min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=13.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=38.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=33.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.9min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=70.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=229.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=32.7min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=140.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=16.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=57.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=33.7min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 3.3min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 7.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=23.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 7.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 7.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=23.6min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.998, total=17.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=57.9min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.995, total=114.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=49.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=29.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=29.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.1min[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total=16.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=37.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=57.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.996, total=60.5min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=294.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.995, total=180.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=376.3min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=32.8min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=34.7min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.998, total=35.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.998, total=185.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=38.4min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.997, total=31.8min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=108.5min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.990, total=232.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=68.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=33.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=33.3min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 3.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.2min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=24.5min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=47.9min
[CV] batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=23.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=56.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=33.4min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=115.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=17.2min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=57.4min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=34.1min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.995, total=115.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=12.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=29.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.998, total=29.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 64, 'output': 1}, score=1.000, total= 2.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=20.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} [CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total=31.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=40.1min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total=61.3min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.997, total=95.9min
[CV] batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=302.7min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=163.2min
[CV] batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.989, total=348.0min
[CV] batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=93.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=62.4min
[CV] batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.996, total=192.0min
[CV] batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=106.7min
[CV] batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=16, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=69.6min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 3.3min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 7.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 7.9min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=29.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=32.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=28.1min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=11.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total=11.0min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=0.998, total=24.2min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=19.4min
[CV] batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=63.8min
[CV] batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.997, total=140.8min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 8.0min
[CV] batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=57.1min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=33.6min
[CV] batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=115.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=57.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=113.8min
[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=20.3min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=49.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'output': 1}, score=0.997, total=29.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=99.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=14.8min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=98.7min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=49.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=29.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=1.000, total=99.6min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=49.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.998, total=29.4min

[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=50.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=29.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.997, total=99.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=49.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.996, total=29.3min

[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=34.0min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=116.0min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=50.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.998, total=98.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total= 6.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=14.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=50.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.998, total=29.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=1.000, total= 6.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.998, total=49.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=98.0min

[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.499, total=50.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=99.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=49.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=29.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=99.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=49.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=97.0min

[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.998, total=34.5min
[CV] batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=64, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=116.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=15.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=12.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=12.2min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=99.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total= 6.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=15.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=15.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=12.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=12.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=1.000, total=98.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=15.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=49.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'output': 1}, score=0.993, total=96.4min

[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 128, 'output': 1}, score=0.999, total=15.0min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=49.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=97.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=1.000, total= 6.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=1.000, total=14.9min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=12.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=0.998, total=12.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=29.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.998, total=97.0min

[CV] batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'output': 1}, score=1.000, total=14.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.1min
[CV] batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=25, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=50.4min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=29.9min
[CV] batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.2, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.500, total=99.9min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 64, 'output': 1}, score=0.999, total=12.4min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'output': 1}, score=1.000, total=29.6min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=1.000, total=29.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 64, 'output': 1}, score=0.999, total= 2.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'output': 1}, score=0.999, total= 6.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'output': 1}, score=1.000, total=20.1min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 256, 'output': 1}, score=1.000, total=49.5min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=29.2min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=97.2min
2020-02-19 14:20:54.678372: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2800000000 Hz
2020-02-19 14:20:54.679615: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5672680 executing computations on platform Host. Devices:
2020-02-19 14:20:54.679652: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>
2020-02-19 14:20:54.769972: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.
[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed: 174.7min
[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed: 1390.8min
[Parallel(n_jobs=-1)]: Done 272 tasks      | elapsed: 2316.0min
[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed: 2900.3min finished
WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.


[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'output': 1}, score=0.999, total=20.1min
[CV] batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=10, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.999, total=20.5min
[CV] batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=25, layers={'input': 256, 'output': 1}, score=0.999, total=49.3min
[CV] batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.5, epochs=50, layers={'input': 256, 'output': 1}, score=0.999, total=97.8min
[CV] batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=10, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 64, 'output': 1}, score=0.999, total= 6.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'output': 1}, score=1.000, total=15.0min
[CV] batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=25, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=15.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 64, 'output': 1}, score=1.000, total=12.4min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'output': 1}, score=0.999, total=29.3min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 128, 'hidden1': 64, 'output': 1}, score=0.999, total=29.7min
[CV] batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1} 
[CV]  batch_size=128, dropout_rate=0.8, epochs=50, layers={'input': 256, 'hidden1': 64, 'hidden2': 256, 'output': 1}, score=0.994, total=96.4min
Best: 0.999677 using {'batch_size': 64, 'dropout_rate': 0.2, 'epochs': 50, 'layers': {'input': 128, 'hidden1': 64, 'output': 1}}
Confusion Matrix:
35022.37 5398.63
37.9 10620.1
f1:  0.7982219968232023
balanced accuracy:  0.9314419775306447
precision:  0.6678350390654805
recall (tpr):  0.9964439857384129
fpr:  0.13356003067712327
aucpr:  0.8325105063524938
Roc_auc score: 0.9314419775306451
