Preparing training and test sets...
Creating samples using as look_back = 400
There are 2546 sequences with 58561 users.
--------------------------------------------------
Current iteration: 0
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (638, 401, 4)
Current test size: (636, 401, 4)
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Training...
2019-10-11 10:29:11.439934: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Epoch 1/3
 - 5s - loss: 0.2095 - acc: 0.9498 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 5s - loss: 0.0119 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 5s - loss: 0.0045 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 16.82085919380188
Training Loss per epoch: [0.20947826355345384, 0.011932219184503006, 0.0044678403195986365]
0.0034584943922646577 1.0 0.0 0.0 0.0
--------------------------------------------------
Current iteration: 1
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (638, 401, 4)
Current test size: (636, 401, 4)
Training...
Epoch 1/3
 - 6s - loss: 0.1349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 5s - loss: 0.0091 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 6s - loss: 0.0040 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 18.747775077819824
Training Loss per epoch: [0.13488148997733398, 0.009060388813408378, 0.003953381615974079]
0.0031835560806962493 1.0 0.0 0.0 0.0
--------------------------------------------------
Current iteration: 0
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (1274, 401, 4)
Current test size: (636, 401, 4)
Training...
Epoch 1/3
 - 11s - loss: 0.1210 - acc: 0.9749 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 12s - loss: 0.0031 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 11s - loss: 0.0017 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 37.141242027282715
Training Loss per epoch: [0.1210225199786376, 0.003050985486938193, 0.0016599007170527496]
0.06375888290041883 0.9905660152435303 0.0 0.0 0.0
--------------------------------------------------
Current iteration: 1
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (1274, 401, 4)
Current test size: (636, 401, 4)
Training...
Epoch 1/3
 - 11s - loss: 0.1056 - acc: 0.9749 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 10s - loss: 0.0021 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 10s - loss: 0.0012 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 34.84897994995117
Training Loss per epoch: [0.1055789652004183, 0.002099456940850702, 0.0011893004602811109]
0.06653485261526182 0.9905660152435303 0.0 0.0 0.0
--------------------------------------------------
Current iteration: 0
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (1910, 401, 4)
Current test size: (636, 401, 4)
Training...
Epoch 1/3
 - 16s - loss: 0.1105 - acc: 0.9634 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 17s - loss: 0.0223 - acc: 0.9969 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 17s - loss: 0.0221 - acc: 0.9969 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 53.81873083114624
Training Loss per epoch: [0.11046322110396717, 0.02229681347121353, 0.02205907358124813]
0.003602134715472846 1.0 0.0 0.0 0.0
--------------------------------------------------
Current iteration: 1
Current number of epochs: 3
Current number of look_backs: 400
Current train size: (1910, 401, 4)
Current test size: (636, 401, 4)
Training...
Epoch 1/3
 - 18s - loss: 0.0936 - acc: 0.9801 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/3
 - 17s - loss: 0.0220 - acc: 0.9969 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/3
 - 17s - loss: 0.0220 - acc: 0.9969 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 56.50685381889343
Training Loss per epoch: [0.09363452129538966, 0.022030308979431763, 0.02202311345761281]
0.0033204405548039285 1.0 0.0 0.0 0.0
       Loss Accuracy F1_score Precision Recall
count     0        0        0         0      0
unique    0        0        0         0      0
top     NaN      NaN      NaN       NaN    NaN
freq    NaN      NaN      NaN       NaN    NaN
PyDev console: starting.

Python 3.6.3 (v3.6.3:2c5fed86e0, Oct  3 2017, 00:32:08) 
[GCC 4.2.1 (Apple Inc. build 5666) (dot 3)] on darwin
