Preparing training and test sets...
Creating samples using as look_back = 5
[[[0.023339804667960932, 0.0, 1.0, 1.0], [0.02191980438396088, 0.0, 1.0, 1.0], [0.021759804351960867, 0.0, 1.0, 1.0], [0.02801980560396112, 0.0, 1.0, 1.0], [0.06073981214796244, 0.0, 1.0, 1.0]], [[0.02191980438396088, 0.0, 1.0, 1.0], [0.021759804351960867, 0.0, 1.0, 1.0], [0.02801980560396112, 0.0, 1.0, 1.0], [0.06073981214796244, 0.0, 1.0, 1.0], [0.031039806207961245, 0.0, 1.0, 1.0]], [[0.021759804351960867, 0.0, 1.0, 1.0], [0.02801980560396112, 0.0, 1.0, 1.0], [0.06073981214796244, 0.0, 1.0, 1.0], [0.031039806207961245, 0.0, 1.0, 1.0], [0.022879804575960914, 0.0, 1.0, 1.0]], [[0.02801980560396112, 0.0, 1.0, 1.0], [0.06073981214796244, 0.0, 1.0, 1.0], [0.031039806207961245, 0.0, 1.0, 1.0], [0.022879804575960914, 0.0, 1.0, 1.0], [0.023099804619960924, 0.0, 1.0, 1.0]], [[0.06073981214796244, 0.0, 1.0, 1.0], [0.031039806207961245, 0.0, 1.0, 1.0], [0.022879804575960914, 0.0, 1.0, 1.0], [0.023099804619960924, 0.0, 1.0, 1.0], [0.02151980430396086, 0.0, 1.0, 1.0]], [[0.031039806207961245, 0.0, 1.0, 1.0], [0.022879804575960914, 0.0, 1.0, 1.0], [0.023099804619960924, 0.0, 1.0, 1.0], [0.02151980430396086, 0.0, 1.0, 1.0], [0.030139806027961208, 0.0, 1.0, 1.0]], [[0.022879804575960914, 0.0, 1.0, 1.0], [0.023099804619960924, 0.0, 1.0, 1.0], [0.02151980430396086, 0.0, 1.0, 1.0], [0.030139806027961208, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0]], [[0.023099804619960924, 0.0, 1.0, 1.0], [0.02151980430396086, 0.0, 1.0, 1.0], [0.030139806027961208, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0]], [[0.02151980430396086, 0.0, 1.0, 1.0], [0.030139806027961208, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.007397801479560297, 0.0, 1.0, 1.0]], [[0.030139806027961208, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.007397801479560297, 0.0, 1.0, 1.0], [0.0175198035039607, 0.0, 1.0, 1.0]], [[0.039999807999961605, 0.0, 1.0, 1.0], [0.039999807999961605, 0.0, 1.0, 1.0], [0.007397801479560297, 0.0, 1.0, 1.0], [0.0175198035039607, 0.0, 1.0, 1.0], [0.02801980560396112, 0.0, 1.0, 1.0]], [[0.07015181403036283, 1.0, 1.0, 1.0], [0.03393100678620136, 1.0, 1.0, 1.0], [0.03287980657596132, 1.0, 1.0, 1.0], [0.035139807027961406, 1.0, 1.0, 1.0], [0.028139805627961128, 1.0, 1.0, 1.0]], [[0.03393100678620136, 1.0, 1.0, 1.0], [0.03287980657596132, 1.0, 1.0, 1.0], [0.035139807027961406, 1.0, 1.0, 1.0], [0.028139805627961128, 1.0, 1.0, 1.0], [0.032299806459961285, 1.0, 1.0, 1.0]], [[0.03287980657596132, 1.0, 1.0, 1.0], [0.035139807027961406, 1.0, 1.0, 1.0], [0.028139805627961128, 1.0, 1.0, 1.0], [0.032299806459961285, 1.0, 1.0, 1.0], [0.016979803395960683, 1.0, 1.0, 1.0]], [[0.03220120644024129, 1.0, 1.0, 1.0], [0.03277980655596131, 1.0, 1.0, 1.0], [0.005473801094760219, 1.0, 1.0, 1.0], [0.048408209681641945, 1.0, 1.0, 1.0], [0.034299806859961375, 1.0, 1.0, 1.0]], [[0.03277980655596131, 1.0, 1.0, 1.0], [0.005473801094760219, 1.0, 1.0, 1.0], [0.048408209681641945, 1.0, 1.0, 1.0], [0.034299806859961375, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0]], [[0.005473801094760219, 1.0, 1.0, 1.0], [0.048408209681641945, 1.0, 1.0, 1.0], [0.034299806859961375, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.015319803063960613, 1.0, 1.0, 1.0]], [[0.048408209681641945, 1.0, 1.0, 1.0], [0.034299806859961375, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.015319803063960613, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.034299806859961375, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.015319803063960613, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05569701113940224, 1.0, 1.0, 1.0]], [[0.015839803167960638, 1.0, 1.0, 1.0], [0.015319803063960613, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05569701113940224, 1.0, 1.0, 1.0], [0.009679801935960387, 1.0, 1.0, 1.0]], [[0.015319803063960613, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05569701113940224, 1.0, 1.0, 1.0], [0.009679801935960387, 1.0, 1.0, 1.0], [0.3068998613799723, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.05569701113940224, 1.0, 1.0, 1.0], [0.009679801935960387, 1.0, 1.0, 1.0], [0.3068998613799723, 1.0, 1.0, 1.0], [0.06305621261124253, 1.0, 1.0, 1.0]], [[0.05569701113940224, 1.0, 1.0, 1.0], [0.009679801935960387, 1.0, 1.0, 1.0], [0.3068998613799723, 1.0, 1.0, 1.0], [0.06305621261124253, 1.0, 1.0, 1.0], [0.0047430009486001895, 1.0, 1.0, 1.0]], [[0.009679801935960387, 1.0, 1.0, 1.0], [0.3068998613799723, 1.0, 1.0, 1.0], [0.06305621261124253, 1.0, 1.0, 1.0], [0.0047430009486001895, 1.0, 1.0, 1.0], [0.056885411377082286, 1.0, 1.0, 1.0]], [[0.3068998613799723, 1.0, 1.0, 1.0], [0.06305621261124253, 1.0, 1.0, 1.0], [0.0047430009486001895, 1.0, 1.0, 1.0], [0.056885411377082286, 1.0, 1.0, 1.0], [0.057073211414642284, 1.0, 1.0, 1.0]], [[0.06305621261124253, 1.0, 1.0, 1.0], [0.0047430009486001895, 1.0, 1.0, 1.0], [0.056885411377082286, 1.0, 1.0, 1.0], [0.057073211414642284, 1.0, 1.0, 1.0], [0.016139803227960645, 1.0, 1.0, 1.0]], [[0.0047430009486001895, 1.0, 1.0, 1.0], [0.056885411377082286, 1.0, 1.0, 1.0], [0.057073211414642284, 1.0, 1.0, 1.0], [0.016139803227960645, 1.0, 1.0, 1.0], [0.0350598070119614, 1.0, 1.0, 1.0]], [[0.056885411377082286, 1.0, 1.0, 1.0], [0.057073211414642284, 1.0, 1.0, 1.0], [0.016139803227960645, 1.0, 1.0, 1.0], [0.0350598070119614, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0]], [[0.057073211414642284, 1.0, 1.0, 1.0], [0.016139803227960645, 1.0, 1.0, 1.0], [0.0350598070119614, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.016139803227960645, 1.0, 1.0, 1.0], [0.0350598070119614, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.01728120345624069, 1.0, 1.0, 1.0]], [[0.0350598070119614, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.01728120345624069, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0]], [[0.015619803123960625, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.01728120345624069, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.026399805279961056, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.01728120345624069, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.026399805279961056, 1.0, 1.0, 1.0], [0.03529980705996141, 1.0, 1.0, 1.0]], [[0.01728120345624069, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.026399805279961056, 1.0, 1.0, 1.0], [0.03529980705996141, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.013879802775960556, 1.0, 1.0, 1.0], [0.026399805279961056, 1.0, 1.0, 1.0], [0.03529980705996141, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.09637021927404388, 1.0, 1.0, 1.0]], [[0.026399805279961056, 1.0, 1.0, 1.0], [0.03529980705996141, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.09637021927404388, 1.0, 1.0, 1.0], [0.03398980679796136, 1.0, 1.0, 1.0]], [[0.03529980705996141, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.09637021927404388, 1.0, 1.0, 1.0], [0.03398980679796136, 1.0, 1.0, 1.0], [0.024563204912640985, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.09637021927404388, 1.0, 1.0, 1.0], [0.03398980679796136, 1.0, 1.0, 1.0], [0.024563204912640985, 1.0, 1.0, 1.0], [0.004064800812960163, 1.0, 1.0, 1.0]], [[0.09637021927404388, 1.0, 1.0, 1.0], [0.03398980679796136, 1.0, 1.0, 1.0], [0.024563204912640985, 1.0, 1.0, 1.0], [0.004064800812960163, 1.0, 1.0, 1.0], [0.002561800512360103, 1.0, 1.0, 1.0]], [[0.03398980679796136, 1.0, 1.0, 1.0], [0.024563204912640985, 1.0, 1.0, 1.0], [0.004064800812960163, 1.0, 1.0, 1.0], [0.002561800512360103, 1.0, 1.0, 1.0], [0.0722698144539629, 1.0, 1.0, 1.0]], [[0.024563204912640985, 1.0, 1.0, 1.0], [0.004064800812960163, 1.0, 1.0, 1.0], [0.002561800512360103, 1.0, 1.0, 1.0], [0.0722698144539629, 1.0, 1.0, 1.0], [0.03112980622596125, 1.0, 1.0, 1.0]], [[0.004064800812960163, 1.0, 1.0, 1.0], [0.002561800512360103, 1.0, 1.0, 1.0], [0.0722698144539629, 1.0, 1.0, 1.0], [0.03112980622596125, 1.0, 1.0, 1.0], [0.00032260006452001296, 1.0, 1.0, 1.0]], [[0.002561800512360103, 1.0, 1.0, 1.0], [0.0722698144539629, 1.0, 1.0, 1.0], [0.03112980622596125, 1.0, 1.0, 1.0], [0.00032260006452001296, 1.0, 1.0, 1.0], [0.015439803087960618, 1.0, 1.0, 1.0]], [[0.0722698144539629, 1.0, 1.0, 1.0], [0.03112980622596125, 1.0, 1.0, 1.0], [0.00032260006452001296, 1.0, 1.0, 1.0], [0.015439803087960618, 1.0, 1.0, 1.0], [0.033399806679961334, 1.0, 1.0, 1.0]], [[0.03112980622596125, 1.0, 1.0, 1.0], [0.00032260006452001296, 1.0, 1.0, 1.0], [0.015439803087960618, 1.0, 1.0, 1.0], [0.033399806679961334, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0]], [[0.00032260006452001296, 1.0, 1.0, 1.0], [0.015439803087960618, 1.0, 1.0, 1.0], [0.033399806679961334, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.015439803087960618, 1.0, 1.0, 1.0], [0.033399806679961334, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.049145609829121965, 1.0, 1.0, 1.0]], [[0.033399806679961334, 1.0, 1.0, 1.0], [0.015839803167960638, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.049145609829121965, 1.0, 1.0, 1.0], [0.036027807205561445, 1.0, 1.0, 1.0]], [[0.015839803167960638, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.049145609829121965, 1.0, 1.0, 1.0], [0.036027807205561445, 1.0, 1.0, 1.0], [0.003304000660800133, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.049145609829121965, 1.0, 1.0, 1.0], [0.036027807205561445, 1.0, 1.0, 1.0], [0.003304000660800133, 1.0, 1.0, 1.0], [0.05151741030348207, 1.0, 1.0, 1.0]], [[0.049145609829121965, 1.0, 1.0, 1.0], [0.036027807205561445, 1.0, 1.0, 1.0], [0.003304000660800133, 1.0, 1.0, 1.0], [0.05151741030348207, 1.0, 1.0, 1.0], [0.03298660659732132, 1.0, 1.0, 1.0]], [[0.036027807205561445, 1.0, 1.0, 1.0], [0.003304000660800133, 1.0, 1.0, 1.0], [0.05151741030348207, 1.0, 1.0, 1.0], [0.03298660659732132, 1.0, 1.0, 1.0], [0.06291981258396252, 1.0, 1.0, 1.0]], [[0.004355800871160175, 1.0, 1.0, 1.0], [0.002435000487000098, 1.0, 1.0, 1.0], [0.02223080444616089, 1.0, 1.0, 1.0], [0.03537980707596142, 1.0, 1.0, 1.0], [0.027499805499961102, 1.0, 1.0, 1.0]], [[0.002435000487000098, 1.0, 1.0, 1.0], [0.02223080444616089, 1.0, 1.0, 1.0], [0.03537980707596142, 1.0, 1.0, 1.0], [0.027499805499961102, 1.0, 1.0, 1.0], [0.035799807159961436, 1.0, 1.0, 1.0]], [[0.02223080444616089, 1.0, 1.0, 1.0], [0.03537980707596142, 1.0, 1.0, 1.0], [0.027499805499961102, 1.0, 1.0, 1.0], [0.035799807159961436, 1.0, 1.0, 1.0], [0.03033980606796122, 1.0, 1.0, 1.0]], [[0.03537980707596142, 1.0, 1.0, 1.0], [0.027499805499961102, 1.0, 1.0, 1.0], [0.035799807159961436, 1.0, 1.0, 1.0], [0.03033980606796122, 1.0, 1.0, 1.0], [0.030619806123961226, 1.0, 1.0, 1.0]], [[0.027499805499961102, 1.0, 1.0, 1.0], [0.035799807159961436, 1.0, 1.0, 1.0], [0.03033980606796122, 1.0, 1.0, 1.0], [0.030619806123961226, 1.0, 1.0, 1.0], [0.02397980479596096, 1.0, 1.0, 1.0]], [[0.035799807159961436, 1.0, 1.0, 1.0], [0.03033980606796122, 1.0, 1.0, 1.0], [0.030619806123961226, 1.0, 1.0, 1.0], [0.02397980479596096, 1.0, 1.0, 1.0], [0.024139804827960968, 1.0, 1.0, 1.0]], [[0.03033980606796122, 1.0, 1.0, 1.0], [0.030619806123961226, 1.0, 1.0, 1.0], [0.02397980479596096, 1.0, 1.0, 1.0], [0.024139804827960968, 1.0, 1.0, 1.0], [0.005538801107760222, 1.0, 1.0, 1.0]], [[0.030619806123961226, 1.0, 1.0, 1.0], [0.02397980479596096, 1.0, 1.0, 1.0], [0.024139804827960968, 1.0, 1.0, 1.0], [0.005538801107760222, 1.0, 1.0, 1.0], [0.013140602628120527, 1.0, 1.0, 1.0]], [[0.02397980479596096, 1.0, 1.0, 1.0], [0.024139804827960968, 1.0, 1.0, 1.0], [0.005538801107760222, 1.0, 1.0, 1.0], [0.013140602628120527, 1.0, 1.0, 1.0], [0.001220800244160049, 1.0, 1.0, 1.0]], [[0.024139804827960968, 1.0, 1.0, 1.0], [0.005538801107760222, 1.0, 1.0, 1.0], [0.013140602628120527, 1.0, 1.0, 1.0], [0.001220800244160049, 1.0, 1.0, 1.0], [0.0017810003562000714, 1.0, 1.0, 1.0]], [[0.005538801107760222, 1.0, 1.0, 1.0], [0.013140602628120527, 1.0, 1.0, 1.0], [0.001220800244160049, 1.0, 1.0, 1.0], [0.0017810003562000714, 1.0, 1.0, 1.0], [0.005611801122360226, 1.0, 1.0, 1.0]], [[0.013140602628120527, 1.0, 1.0, 1.0], [0.001220800244160049, 1.0, 1.0, 1.0], [0.0017810003562000714, 1.0, 1.0, 1.0], [0.005611801122360226, 1.0, 1.0, 1.0], [0.09759981951996392, 1.0, 1.0, 1.0]], [[0.001220800244160049, 1.0, 1.0, 1.0], [0.0017810003562000714, 1.0, 1.0, 1.0], [0.005611801122360226, 1.0, 1.0, 1.0], [0.09759981951996392, 1.0, 1.0, 1.0], [0.004930000986000198, 1.0, 1.0, 1.0]], [[0.0017810003562000714, 1.0, 1.0, 1.0], [0.005611801122360226, 1.0, 1.0, 1.0], [0.09759981951996392, 1.0, 1.0, 1.0], [0.004930000986000198, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.005611801122360226, 1.0, 1.0, 1.0], [0.09759981951996392, 1.0, 1.0, 1.0], [0.004930000986000198, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.02703980540796108, 1.0, 1.0, 1.0]], [[0.09759981951996392, 1.0, 1.0, 1.0], [0.004930000986000198, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.02703980540796108, 1.0, 1.0, 1.0], [0.02027980405596081, 1.0, 1.0, 1.0]], [[0.004930000986000198, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.02703980540796108, 1.0, 1.0, 1.0], [0.02027980405596081, 1.0, 1.0, 1.0], [0.04375980875196176, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.02703980540796108, 1.0, 1.0, 1.0], [0.02027980405596081, 1.0, 1.0, 1.0], [0.04375980875196176, 1.0, 1.0, 1.0], [0.027619805523961108, 1.0, 1.0, 1.0]], [[0.02703980540796108, 1.0, 1.0, 1.0], [0.02027980405596081, 1.0, 1.0, 1.0], [0.04375980875196176, 1.0, 1.0, 1.0], [0.027619805523961108, 1.0, 1.0, 1.0], [0.03203980640796129, 1.0, 1.0, 1.0]], [[0.02027980405596081, 1.0, 1.0, 1.0], [0.04375980875196176, 1.0, 1.0, 1.0], [0.027619805523961108, 1.0, 1.0, 1.0], [0.03203980640796129, 1.0, 1.0, 1.0], [0.025339805067961012, 1.0, 1.0, 1.0]], [[0.04375980875196176, 1.0, 1.0, 1.0], [0.027619805523961108, 1.0, 1.0, 1.0], [0.03203980640796129, 1.0, 1.0, 1.0], [0.025339805067961012, 1.0, 1.0, 1.0], [0.025519805103961023, 1.0, 1.0, 1.0]], [[0.027619805523961108, 1.0, 1.0, 1.0], [0.03203980640796129, 1.0, 1.0, 1.0], [0.025339805067961012, 1.0, 1.0, 1.0], [0.025519805103961023, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0]], [[0.03203980640796129, 1.0, 1.0, 1.0], [0.025339805067961012, 1.0, 1.0, 1.0], [0.025519805103961023, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.021804604360920875, 1.0, 1.0, 1.0]], [[0.025339805067961012, 1.0, 1.0, 1.0], [0.025519805103961023, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.021804604360920875, 1.0, 1.0, 1.0], [0.00798780159756032, 1.0, 1.0, 1.0]], [[0.025519805103961023, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.021804604360920875, 1.0, 1.0, 1.0], [0.00798780159756032, 1.0, 1.0, 1.0], [0.008939801787960359, 1.0, 1.0, 1.0]], [[0.07999981599996321, 1.0, 1.0, 1.0], [0.021804604360920875, 1.0, 1.0, 1.0], [0.00798780159756032, 1.0, 1.0, 1.0], [0.008939801787960359, 1.0, 1.0, 1.0], [0.053439810687962136, 1.0, 1.0, 1.0]], [[0.021804604360920875, 1.0, 1.0, 1.0], [0.00798780159756032, 1.0, 1.0, 1.0], [0.008939801787960359, 1.0, 1.0, 1.0], [0.053439810687962136, 1.0, 1.0, 1.0], [0.04275180855036171, 1.0, 1.0, 1.0]], [[0.00798780159756032, 1.0, 1.0, 1.0], [0.008939801787960359, 1.0, 1.0, 1.0], [0.053439810687962136, 1.0, 1.0, 1.0], [0.04275180855036171, 1.0, 1.0, 1.0], [0.02528720505744101, 1.0, 1.0, 1.0]], [[0.008939801787960359, 1.0, 1.0, 1.0], [0.053439810687962136, 1.0, 1.0, 1.0], [0.04275180855036171, 1.0, 1.0, 1.0], [0.02528720505744101, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0]], [[0.053439810687962136, 1.0, 1.0, 1.0], [0.04275180855036171, 1.0, 1.0, 1.0], [0.02528720505744101, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.031739806347961266, 1.0, 1.0, 1.0]], [[0.04275180855036171, 1.0, 1.0, 1.0], [0.02528720505744101, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.031739806347961266, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0]], [[0.02528720505744101, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.031739806347961266, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.02827980565596113, 1.0, 1.0, 1.0]], [[0.023999804799960958, 1.0, 1.0, 1.0], [0.031739806347961266, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.02827980565596113, 1.0, 1.0, 1.0], [0.0225198045039609, 1.0, 1.0, 1.0]], [[0.031739806347961266, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.02827980565596113, 1.0, 1.0, 1.0], [0.0225198045039609, 1.0, 1.0, 1.0], [0.026239805247961046, 1.0, 1.0, 1.0]], [[0.024559804911960983, 1.0, 1.0, 1.0], [0.02827980565596113, 1.0, 1.0, 1.0], [0.0225198045039609, 1.0, 1.0, 1.0], [0.026239805247961046, 1.0, 1.0, 1.0], [0.00035100007020001406, 1.0, 1.0, 1.0]], [[0.02827980565596113, 1.0, 1.0, 1.0], [0.0225198045039609, 1.0, 1.0, 1.0], [0.026239805247961046, 1.0, 1.0, 1.0], [0.00035100007020001406, 1.0, 1.0, 1.0], [0.003699800739960149, 1.0, 1.0, 1.0]], [[0.0225198045039609, 1.0, 1.0, 1.0], [0.026239805247961046, 1.0, 1.0, 1.0], [0.00035100007020001406, 1.0, 1.0, 1.0], [0.003699800739960149, 1.0, 1.0, 1.0], [0.002039800407960082, 1.0, 1.0, 1.0]], [[0.026239805247961046, 1.0, 1.0, 1.0], [0.00035100007020001406, 1.0, 1.0, 1.0], [0.003699800739960149, 1.0, 1.0, 1.0], [0.002039800407960082, 1.0, 1.0, 1.0], [0.0050140010028002025, 1.0, 1.0, 1.0]], [[0.00035100007020001406, 1.0, 1.0, 1.0], [0.003699800739960149, 1.0, 1.0, 1.0], [0.002039800407960082, 1.0, 1.0, 1.0], [0.0050140010028002025, 1.0, 1.0, 1.0], [0.0009172001834400367, 1.0, 1.0, 1.0]], [[0.003699800739960149, 1.0, 1.0, 1.0], [0.002039800407960082, 1.0, 1.0, 1.0], [0.0050140010028002025, 1.0, 1.0, 1.0], [0.0009172001834400367, 1.0, 1.0, 1.0], [0.00919580183916037, 1.0, 1.0, 1.0]], [[0.002039800407960082, 1.0, 1.0, 1.0], [0.0050140010028002025, 1.0, 1.0, 1.0], [0.0009172001834400367, 1.0, 1.0, 1.0], [0.00919580183916037, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0]], [[0.0050140010028002025, 1.0, 1.0, 1.0], [0.0009172001834400367, 1.0, 1.0, 1.0], [0.00919580183916037, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [9.740001948000392e-05, 1.0, 1.0, 1.0]], [[0.0009172001834400367, 1.0, 1.0, 1.0], [0.00919580183916037, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [9.740001948000392e-05, 1.0, 1.0, 1.0], [0.00622780124556025, 1.0, 1.0, 1.0]], [[0.00919580183916037, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [9.740001948000392e-05, 1.0, 1.0, 1.0], [0.00622780124556025, 1.0, 1.0, 1.0], [0.017144403428880687, 1.0, 1.0, 1.0]], [[0.0017998003599600722, 1.0, 1.0, 1.0], [9.740001948000392e-05, 1.0, 1.0, 1.0], [0.00622780124556025, 1.0, 1.0, 1.0], [0.017144403428880687, 1.0, 1.0, 1.0], [0.008139401627880327, 1.0, 1.0, 1.0]], [[9.740001948000392e-05, 1.0, 1.0, 1.0], [0.00622780124556025, 1.0, 1.0, 1.0], [0.017144403428880687, 1.0, 1.0, 1.0], [0.008139401627880327, 1.0, 1.0, 1.0], [0.013399802679960538, 1.0, 1.0, 1.0]], [[0.00622780124556025, 1.0, 1.0, 1.0], [0.017144403428880687, 1.0, 1.0, 1.0], [0.008139401627880327, 1.0, 1.0, 1.0], [0.013399802679960538, 1.0, 1.0, 1.0], [0.0049808009961602, 1.0, 1.0, 1.0]], [[0.017144403428880687, 1.0, 1.0, 1.0], [0.008139401627880327, 1.0, 1.0, 1.0], [0.013399802679960538, 1.0, 1.0, 1.0], [0.0049808009961602, 1.0, 1.0, 1.0], [0.026319805263961053, 1.0, 1.0, 1.0]], [[0.008139401627880327, 1.0, 1.0, 1.0], [0.013399802679960538, 1.0, 1.0, 1.0], [0.0049808009961602, 1.0, 1.0, 1.0], [0.026319805263961053, 1.0, 1.0, 1.0], [0.032179806435961286, 1.0, 1.0, 1.0]], [[0.013399802679960538, 1.0, 1.0, 1.0], [0.0049808009961602, 1.0, 1.0, 1.0], [0.026319805263961053, 1.0, 1.0, 1.0], [0.032179806435961286, 1.0, 1.0, 1.0], [0.024919804983961, 1.0, 1.0, 1.0]], [[0.0049808009961602, 1.0, 1.0, 1.0], [0.026319805263961053, 1.0, 1.0, 1.0], [0.032179806435961286, 1.0, 1.0, 1.0], [0.024919804983961, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0]], [[0.026319805263961053, 1.0, 1.0, 1.0], [0.032179806435961286, 1.0, 1.0, 1.0], [0.024919804983961, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.02409980481996097, 1.0, 1.0, 1.0]], [[0.032179806435961286, 1.0, 1.0, 1.0], [0.024919804983961, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.02409980481996097, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0]], [[0.024919804983961, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.02409980481996097, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.001619800323960065, 1.0, 1.0, 1.0]], [[0.03161980632396127, 1.0, 1.0, 1.0], [0.02409980481996097, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.001619800323960065, 1.0, 1.0, 1.0], [0.04940700988140198, 1.0, 1.0, 1.0]], [[0.02409980481996097, 1.0, 1.0, 1.0], [0.024559804911960983, 1.0, 1.0, 1.0], [0.001619800323960065, 1.0, 1.0, 1.0], [0.04940700988140198, 1.0, 1.0, 1.0], [0.006647201329440267, 1.0, 1.0, 1.0]], [[0.024559804911960983, 1.0, 1.0, 1.0], [0.001619800323960065, 1.0, 1.0, 1.0], [0.04940700988140198, 1.0, 1.0, 1.0], [0.006647201329440267, 1.0, 1.0, 1.0], [0.0014532002906400582, 1.0, 1.0, 1.0]], [[0.001619800323960065, 1.0, 1.0, 1.0], [0.04940700988140198, 1.0, 1.0, 1.0], [0.006647201329440267, 1.0, 1.0, 1.0], [0.0014532002906400582, 1.0, 1.0, 1.0], [0.0699998139999628, 1.0, 1.0, 1.0]], [[0.04116900823380165, 1.0, 1.0, 1.0], [0.010750602150120431, 1.0, 1.0, 1.0], [0.05191981038396208, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.010750602150120431, 1.0, 1.0, 1.0], [0.05191981038396208, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.012512002502400504, 1.0, 1.0, 1.0]], [[0.05191981038396208, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.012512002502400504, 1.0, 1.0, 1.0], [0.010150202030040406, 1.0, 1.0, 1.0]], [[0.3999998799999761, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.012512002502400504, 1.0, 1.0, 1.0], [0.010150202030040406, 1.0, 1.0, 1.0], [0.009271801854360372, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.012512002502400504, 1.0, 1.0, 1.0], [0.010150202030040406, 1.0, 1.0, 1.0], [0.009271801854360372, 1.0, 1.0, 1.0], [0.5599999119999824, 1.0, 1.0, 1.0]], [[0.012512002502400504, 1.0, 1.0, 1.0], [0.010150202030040406, 1.0, 1.0, 1.0], [0.009271801854360372, 1.0, 1.0, 1.0], [0.5599999119999824, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0]], [[0.010150202030040406, 1.0, 1.0, 1.0], [0.009271801854360372, 1.0, 1.0, 1.0], [0.5599999119999824, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.015053603010720604, 1.0, 1.0, 1.0]], [[0.009271801854360372, 1.0, 1.0, 1.0], [0.5599999119999824, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.015053603010720604, 1.0, 1.0, 1.0], [0.008999801799960362, 1.0, 1.0, 1.0]], [[0.015999803199960642, 1.0, 1.0, 1.0], [0.004031800806360162, 1.0, 1.0, 1.0], [0.049999809999962, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.004031800806360162, 1.0, 1.0, 1.0], [0.049999809999962, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.048459809691961946, 1.0, 1.0, 1.0]], [[0.049999809999962, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.048459809691961946, 1.0, 1.0, 1.0], [0.034839806967961386, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.048459809691961946, 1.0, 1.0, 1.0], [0.034839806967961386, 1.0, 1.0, 1.0], [0.03319980663996133, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.048459809691961946, 1.0, 1.0, 1.0], [0.034839806967961386, 1.0, 1.0, 1.0], [0.03319980663996133, 1.0, 1.0, 1.0], [0.05155981031196207, 1.0, 1.0, 1.0]], [[0.048459809691961946, 1.0, 1.0, 1.0], [0.034839806967961386, 1.0, 1.0, 1.0], [0.03319980663996133, 1.0, 1.0, 1.0], [0.05155981031196207, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0]], [[0.034839806967961386, 1.0, 1.0, 1.0], [0.03319980663996133, 1.0, 1.0, 1.0], [0.05155981031196207, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.019699803939960788, 1.0, 1.0, 1.0]], [[0.03319980663996133, 1.0, 1.0, 1.0], [0.05155981031196207, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.019699803939960788, 1.0, 1.0, 1.0], [0.0424198084839617, 1.0, 1.0, 1.0]], [[0.05155981031196207, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.019699803939960788, 1.0, 1.0, 1.0], [0.0424198084839617, 1.0, 1.0, 1.0], [0.03371980674396135, 1.0, 1.0, 1.0]], [[0.013639802727960549, 1.0, 1.0, 1.0], [0.019699803939960788, 1.0, 1.0, 1.0], [0.0424198084839617, 1.0, 1.0, 1.0], [0.03371980674396135, 1.0, 1.0, 1.0], [0.0017520003504000704, 1.0, 1.0, 1.0]], [[0.019699803939960788, 1.0, 1.0, 1.0], [0.0424198084839617, 1.0, 1.0, 1.0], [0.03371980674396135, 1.0, 1.0, 1.0], [0.0017520003504000704, 1.0, 1.0, 1.0], [0.03649980729996146, 1.0, 1.0, 1.0]], [[0.0424198084839617, 1.0, 1.0, 1.0], [0.03371980674396135, 1.0, 1.0, 1.0], [0.0017520003504000704, 1.0, 1.0, 1.0], [0.03649980729996146, 1.0, 1.0, 1.0], [0.03447980689596138, 1.0, 1.0, 1.0]], [[0.03371980674396135, 1.0, 1.0, 1.0], [0.0017520003504000704, 1.0, 1.0, 1.0], [0.03649980729996146, 1.0, 1.0, 1.0], [0.03447980689596138, 1.0, 1.0, 1.0], [0.0006198001239600249, 1.0, 1.0, 1.0]], [[0.0017520003504000704, 1.0, 1.0, 1.0], [0.03649980729996146, 1.0, 1.0, 1.0], [0.03447980689596138, 1.0, 1.0, 1.0], [0.0006198001239600249, 1.0, 1.0, 1.0], [0.030079806015961205, 1.0, 1.0, 1.0]], [[0.03649980729996146, 1.0, 1.0, 1.0], [0.03447980689596138, 1.0, 1.0, 1.0], [0.0006198001239600249, 1.0, 1.0, 1.0], [0.030079806015961205, 1.0, 1.0, 1.0], [0.00821980164396033, 1.0, 1.0, 1.0]], [[0.03447980689596138, 1.0, 1.0, 1.0], [0.0006198001239600249, 1.0, 1.0, 1.0], [0.030079806015961205, 1.0, 1.0, 1.0], [0.00821980164396033, 1.0, 1.0, 1.0], [0.027839805567961114, 1.0, 1.0, 1.0]], [[0.0006198001239600249, 1.0, 1.0, 1.0], [0.030079806015961205, 1.0, 1.0, 1.0], [0.00821980164396033, 1.0, 1.0, 1.0], [0.027839805567961114, 1.0, 1.0, 1.0], [0.037879807575961516, 1.0, 1.0, 1.0]], [[0.030079806015961205, 1.0, 1.0, 1.0], [0.00821980164396033, 1.0, 1.0, 1.0], [0.027839805567961114, 1.0, 1.0, 1.0], [0.037879807575961516, 1.0, 1.0, 1.0], [0.018859803771960757, 1.0, 1.0, 1.0]], [[0.00821980164396033, 1.0, 1.0, 1.0], [0.027839805567961114, 1.0, 1.0, 1.0], [0.037879807575961516, 1.0, 1.0, 1.0], [0.018859803771960757, 1.0, 1.0, 1.0], [0.014159802831960569, 1.0, 1.0, 1.0]], [[0.027839805567961114, 1.0, 1.0, 1.0], [0.037879807575961516, 1.0, 1.0, 1.0], [0.018859803771960757, 1.0, 1.0, 1.0], [0.014159802831960569, 1.0, 1.0, 1.0], [0.036399807279961456, 1.0, 1.0, 1.0]], [[0.037879807575961516, 1.0, 1.0, 1.0], [0.018859803771960757, 1.0, 1.0, 1.0], [0.014159802831960569, 1.0, 1.0, 1.0], [0.036399807279961456, 1.0, 1.0, 1.0], [0.040599808119961625, 1.0, 1.0, 1.0]], [[0.018859803771960757, 1.0, 1.0, 1.0], [0.014159802831960569, 1.0, 1.0, 1.0], [0.036399807279961456, 1.0, 1.0, 1.0], [0.040599808119961625, 1.0, 1.0, 1.0], [0.013019802603960523, 1.0, 1.0, 1.0]], [[0.014159802831960569, 1.0, 1.0, 1.0], [0.036399807279961456, 1.0, 1.0, 1.0], [0.040599808119961625, 1.0, 1.0, 1.0], [0.013019802603960523, 1.0, 1.0, 1.0], [0.01971980394396079, 1.0, 1.0, 1.0]], [[0.036399807279961456, 1.0, 1.0, 1.0], [0.040599808119961625, 1.0, 1.0, 1.0], [0.013019802603960523, 1.0, 1.0, 1.0], [0.01971980394396079, 1.0, 1.0, 1.0], [0.02029980405996081, 1.0, 1.0, 1.0]], [[0.040599808119961625, 1.0, 1.0, 1.0], [0.013019802603960523, 1.0, 1.0, 1.0], [0.01971980394396079, 1.0, 1.0, 1.0], [0.02029980405996081, 1.0, 1.0, 1.0], [0.025039805007961, 1.0, 1.0, 1.0]], [[0.013019802603960523, 1.0, 1.0, 1.0], [0.01971980394396079, 1.0, 1.0, 1.0], [0.02029980405996081, 1.0, 1.0, 1.0], [0.025039805007961, 1.0, 1.0, 1.0], [0.06261981252396251, 1.0, 1.0, 1.0]], [[0.01971980394396079, 1.0, 1.0, 1.0], [0.02029980405996081, 1.0, 1.0, 1.0], [0.025039805007961, 1.0, 1.0, 1.0], [0.06261981252396251, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0]], [[0.02029980405996081, 1.0, 1.0, 1.0], [0.025039805007961, 1.0, 1.0, 1.0], [0.06261981252396251, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0]], [[0.025039805007961, 1.0, 1.0, 1.0], [0.06261981252396251, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.023499804699960943, 1.0, 1.0, 1.0]], [[0.06261981252396251, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.023499804699960943, 1.0, 1.0, 1.0], [0.03273980654796131, 1.0, 1.0, 1.0]], [[0.002459800491960099, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.023499804699960943, 1.0, 1.0, 1.0], [0.03273980654796131, 1.0, 1.0, 1.0], [0.03839980767996154, 1.0, 1.0, 1.0]], [[0.0274598054919611, 1.0, 1.0, 1.0], [0.023499804699960943, 1.0, 1.0, 1.0], [0.03273980654796131, 1.0, 1.0, 1.0], [0.03839980767996154, 1.0, 1.0, 1.0], [0.002679800535960108, 1.0, 1.0, 1.0]], [[0.023499804699960943, 1.0, 1.0, 1.0], [0.03273980654796131, 1.0, 1.0, 1.0], [0.03839980767996154, 1.0, 1.0, 1.0], [0.002679800535960108, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0]], [[0.03273980654796131, 1.0, 1.0, 1.0], [0.03839980767996154, 1.0, 1.0, 1.0], [0.002679800535960108, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.011999802399960482, 1.0, 1.0, 1.0]], [[0.03839980767996154, 1.0, 1.0, 1.0], [0.002679800535960108, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.011999802399960482, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0]], [[0.002679800535960108, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.011999802399960482, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0]], [[0.007999801599960322, 1.0, 1.0, 1.0], [0.011999802399960482, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.02871980574396115, 1.0, 1.0, 1.0]], [[0.011999802399960482, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.02871980574396115, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0]], [[0.019179803835960768, 1.0, 1.0, 1.0], [0.019179803835960768, 1.0, 1.0, 1.0], [0.02871980574396115, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.024759804951960996, 1.0, 1.0, 1.0]], [[0.019179803835960768, 1.0, 1.0, 1.0], [0.02871980574396115, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.024759804951960996, 1.0, 1.0, 1.0], [0.010159802031960407, 1.0, 1.0, 1.0]], [[0.02871980574396115, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.024759804951960996, 1.0, 1.0, 1.0], [0.010159802031960407, 1.0, 1.0, 1.0], [0.028619805723961143, 1.0, 1.0, 1.0]], [[0.030179806035961213, 1.0, 1.0, 1.0], [0.024759804951960996, 1.0, 1.0, 1.0], [0.010159802031960407, 1.0, 1.0, 1.0], [0.028619805723961143, 1.0, 1.0, 1.0], [0.027139805427961086, 1.0, 1.0, 1.0]], [[0.024759804951960996, 1.0, 1.0, 1.0], [0.010159802031960407, 1.0, 1.0, 1.0], [0.028619805723961143, 1.0, 1.0, 1.0], [0.027139805427961086, 1.0, 1.0, 1.0], [0.03609980721996145, 1.0, 1.0, 1.0]], [[0.010159802031960407, 1.0, 1.0, 1.0], [0.028619805723961143, 1.0, 1.0, 1.0], [0.027139805427961086, 1.0, 1.0, 1.0], [0.03609980721996145, 1.0, 1.0, 1.0], [0.022019804403960886, 1.0, 1.0, 1.0]], [[0.028619805723961143, 1.0, 1.0, 1.0], [0.027139805427961086, 1.0, 1.0, 1.0], [0.03609980721996145, 1.0, 1.0, 1.0], [0.022019804403960886, 1.0, 1.0, 1.0], [0.01909980381996076, 1.0, 1.0, 1.0]], [[0.027139805427961086, 1.0, 1.0, 1.0], [0.03609980721996145, 1.0, 1.0, 1.0], [0.022019804403960886, 1.0, 1.0, 1.0], [0.01909980381996076, 1.0, 1.0, 1.0], [0.04323980864796173, 1.0, 1.0, 1.0]], [[0.03609980721996145, 1.0, 1.0, 1.0], [0.022019804403960886, 1.0, 1.0, 1.0], [0.01909980381996076, 1.0, 1.0, 1.0], [0.04323980864796173, 1.0, 1.0, 1.0], [0.045459809091961824, 1.0, 1.0, 1.0]], [[0.022019804403960886, 1.0, 1.0, 1.0], [0.01909980381996076, 1.0, 1.0, 1.0], [0.04323980864796173, 1.0, 1.0, 1.0], [0.045459809091961824, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0]], [[0.01909980381996076, 1.0, 1.0, 1.0], [0.04323980864796173, 1.0, 1.0, 1.0], [0.045459809091961824, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0]], [[0.04323980864796173, 1.0, 1.0, 1.0], [0.045459809091961824, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0]], [[0.045459809091961824, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.02371980474396095, 1.0, 1.0, 1.0]], [[0.009999801999960402, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.02371980474396095, 1.0, 1.0, 1.0], [0.02389980477996096, 1.0, 1.0, 1.0]], [[0.0199998039999608, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.02371980474396095, 1.0, 1.0, 1.0], [0.02389980477996096, 1.0, 1.0, 1.0], [0.018419803683960737, 1.0, 1.0, 1.0]], [[0.004999800999960201, 1.0, 1.0, 1.0], [0.02371980474396095, 1.0, 1.0, 1.0], [0.02389980477996096, 1.0, 1.0, 1.0], [0.018419803683960737, 1.0, 1.0, 1.0], [0.022859804571960917, 1.0, 1.0, 1.0]], [[0.02371980474396095, 1.0, 1.0, 1.0], [0.02389980477996096, 1.0, 1.0, 1.0], [0.018419803683960737, 1.0, 1.0, 1.0], [0.022859804571960917, 1.0, 1.0, 1.0], [0.030519806103961218, 1.0, 1.0, 1.0]], [[0.02389980477996096, 1.0, 1.0, 1.0], [0.018419803683960737, 1.0, 1.0, 1.0], [0.022859804571960917, 1.0, 1.0, 1.0], [0.030519806103961218, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0]], [[0.018419803683960737, 1.0, 1.0, 1.0], [0.022859804571960917, 1.0, 1.0, 1.0], [0.030519806103961218, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0]], [[0.022859804571960917, 1.0, 1.0, 1.0], [0.030519806103961218, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.01817980363596073, 1.0, 1.0, 1.0]], [[0.030519806103961218, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.01817980363596073, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0]], [[0.002089800417960084, 1.0, 1.0, 1.0], [0.002089800417960084, 1.0, 1.0, 1.0], [0.01817980363596073, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0]], [[0.002089800417960084, 1.0, 1.0, 1.0], [0.01817980363596073, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0]], [[0.01817980363596073, 1.0, 1.0, 1.0], [0.004999800999960201, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.004999800999960201, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.007999801599960322, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.07999981599996321, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.026899805379961082, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.026899805379961082, 1.0, 1.0, 1.0], [0.029499805899961182, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.026899805379961082, 1.0, 1.0, 1.0], [0.029499805899961182, 1.0, 1.0, 1.0], [0.02377980475596095, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.026899805379961082, 1.0, 1.0, 1.0], [0.029499805899961182, 1.0, 1.0, 1.0], [0.02377980475596095, 1.0, 1.0, 1.0], [0.019339803867960772, 1.0, 1.0, 1.0]], [[0.026899805379961082, 1.0, 1.0, 1.0], [0.029499805899961182, 1.0, 1.0, 1.0], [0.02377980475596095, 1.0, 1.0, 1.0], [0.019339803867960772, 1.0, 1.0, 1.0], [0.004199800839960168, 1.0, 1.0, 1.0]], [[0.029499805899961182, 1.0, 1.0, 1.0], [0.02377980475596095, 1.0, 1.0, 1.0], [0.019339803867960772, 1.0, 1.0, 1.0], [0.004199800839960168, 1.0, 1.0, 1.0], [0.0299398059879612, 1.0, 1.0, 1.0]], [[0.02377980475596095, 1.0, 1.0, 1.0], [0.019339803867960772, 1.0, 1.0, 1.0], [0.004199800839960168, 1.0, 1.0, 1.0], [0.0299398059879612, 1.0, 1.0, 1.0], [0.013659802731960548, 1.0, 1.0, 1.0]], [[0.019339803867960772, 1.0, 1.0, 1.0], [0.004199800839960168, 1.0, 1.0, 1.0], [0.0299398059879612, 1.0, 1.0, 1.0], [0.013659802731960548, 1.0, 1.0, 1.0], [0.03583980716796144, 1.0, 1.0, 1.0]], [[0.004199800839960168, 1.0, 1.0, 1.0], [0.0299398059879612, 1.0, 1.0, 1.0], [0.013659802731960548, 1.0, 1.0, 1.0], [0.03583980716796144, 1.0, 1.0, 1.0], [0.03543980708796142, 1.0, 1.0, 1.0]], [[0.0299398059879612, 1.0, 1.0, 1.0], [0.013659802731960548, 1.0, 1.0, 1.0], [0.03583980716796144, 1.0, 1.0, 1.0], [0.03543980708796142, 1.0, 1.0, 1.0], [0.007619801523960306, 1.0, 1.0, 1.0]], [[0.013659802731960548, 1.0, 1.0, 1.0], [0.03583980716796144, 1.0, 1.0, 1.0], [0.03543980708796142, 1.0, 1.0, 1.0], [0.007619801523960306, 1.0, 1.0, 1.0], [0.035519807103961416, 1.0, 1.0, 1.0]], [[0.03583980716796144, 1.0, 1.0, 1.0], [0.03543980708796142, 1.0, 1.0, 1.0], [0.007619801523960306, 1.0, 1.0, 1.0], [0.035519807103961416, 1.0, 1.0, 1.0], [0.0375798075159615, 1.0, 1.0, 1.0]], [[0.03543980708796142, 1.0, 1.0, 1.0], [0.007619801523960306, 1.0, 1.0, 1.0], [0.035519807103961416, 1.0, 1.0, 1.0], [0.0375798075159615, 1.0, 1.0, 1.0], [0.02331980466396093, 1.0, 1.0, 1.0]], [[0.007619801523960306, 1.0, 1.0, 1.0], [0.035519807103961416, 1.0, 1.0, 1.0], [0.0375798075159615, 1.0, 1.0, 1.0], [0.02331980466396093, 1.0, 1.0, 1.0], [0.03581980716396144, 1.0, 1.0, 1.0]], [[0.035519807103961416, 1.0, 1.0, 1.0], [0.0375798075159615, 1.0, 1.0, 1.0], [0.02331980466396093, 1.0, 1.0, 1.0], [0.03581980716396144, 1.0, 1.0, 1.0], [0.032319806463961286, 1.0, 1.0, 1.0]], [[0.0375798075159615, 1.0, 1.0, 1.0], [0.02331980466396093, 1.0, 1.0, 1.0], [0.03581980716396144, 1.0, 1.0, 1.0], [0.032319806463961286, 1.0, 1.0, 1.0], [0.018439803687960738, 1.0, 1.0, 1.0]], [[0.02331980466396093, 1.0, 1.0, 1.0], [0.03581980716396144, 1.0, 1.0, 1.0], [0.032319806463961286, 1.0, 1.0, 1.0], [0.018439803687960738, 1.0, 1.0, 1.0], [0.026799805359961074, 1.0, 1.0, 1.0]], [[0.03581980716396144, 1.0, 1.0, 1.0], [0.032319806463961286, 1.0, 1.0, 1.0], [0.018439803687960738, 1.0, 1.0, 1.0], [0.026799805359961074, 1.0, 1.0, 1.0], [0.017319803463960694, 1.0, 1.0, 1.0]], [[0.032319806463961286, 1.0, 1.0, 1.0], [0.018439803687960738, 1.0, 1.0, 1.0], [0.026799805359961074, 1.0, 1.0, 1.0], [0.017319803463960694, 1.0, 1.0, 1.0], [0.02833980566796113, 1.0, 1.0, 1.0]], [[0.018439803687960738, 1.0, 1.0, 1.0], [0.026799805359961074, 1.0, 1.0, 1.0], [0.017319803463960694, 1.0, 1.0, 1.0], [0.02833980566796113, 1.0, 1.0, 1.0], [0.017559803511960702, 1.0, 1.0, 1.0]], [[0.026799805359961074, 1.0, 1.0, 1.0], [0.017319803463960694, 1.0, 1.0, 1.0], [0.02833980566796113, 1.0, 1.0, 1.0], [0.017559803511960702, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0]], [[0.017319803463960694, 1.0, 1.0, 1.0], [0.02833980566796113, 1.0, 1.0, 1.0], [0.017559803511960702, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0]], [[0.02833980566796113, 1.0, 1.0, 1.0], [0.017559803511960702, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0], [0.022419804483960897, 1.0, 1.0, 1.0]], [[0.017559803511960702, 1.0, 1.0, 1.0], [0.03161980632396127, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0], [0.022419804483960897, 1.0, 1.0, 1.0], [0.005088801017760204, 1.0, 1.0, 1.0]], [[0.03161980632396127, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0], [0.022419804483960897, 1.0, 1.0, 1.0], [0.005088801017760204, 1.0, 1.0, 1.0], [0.020559804111960824, 1.0, 1.0, 1.0]], [[0.03815980763196153, 1.0, 1.0, 1.0], [0.022419804483960897, 1.0, 1.0, 1.0], [0.005088801017760204, 1.0, 1.0, 1.0], [0.020559804111960824, 1.0, 1.0, 1.0], [0.0029398005879601183, 1.0, 1.0, 1.0]], [[0.022419804483960897, 1.0, 1.0, 1.0], [0.005088801017760204, 1.0, 1.0, 1.0], [0.020559804111960824, 1.0, 1.0, 1.0], [0.0029398005879601183, 1.0, 1.0, 1.0], [0.002519800503960101, 1.0, 1.0, 1.0]], [[0.005088801017760204, 1.0, 1.0, 1.0], [0.020559804111960824, 1.0, 1.0, 1.0], [0.0029398005879601183, 1.0, 1.0, 1.0], [0.002519800503960101, 1.0, 1.0, 1.0], [0.031079806215961243, 1.0, 1.0, 1.0]], [[0.020559804111960824, 1.0, 1.0, 1.0], [0.0029398005879601183, 1.0, 1.0, 1.0], [0.002519800503960101, 1.0, 1.0, 1.0], [0.031079806215961243, 1.0, 1.0, 1.0], [0.03165980633196127, 1.0, 1.0, 1.0]], [[0.0029398005879601183, 1.0, 1.0, 1.0], [0.002519800503960101, 1.0, 1.0, 1.0], [0.031079806215961243, 1.0, 1.0, 1.0], [0.03165980633196127, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0]], [[0.002519800503960101, 1.0, 1.0, 1.0], [0.031079806215961243, 1.0, 1.0, 1.0], [0.03165980633196127, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0]], [[0.031079806215961243, 1.0, 1.0, 1.0], [0.03165980633196127, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.019379803875960774, 1.0, 1.0, 1.0]], [[0.03165980633196127, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.019379803875960774, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0]], [[0.030879806175961238, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.019379803875960774, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0]], [[0.018839803767960756, 1.0, 1.0, 1.0], [0.019379803875960774, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0]], [[0.019379803875960774, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.012999802599960522, 1.0, 1.0, 1.0]], [[0.03331980666396134, 1.0, 1.0, 1.0], [0.03331980666396134, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.012999802599960522, 1.0, 1.0, 1.0], [0.006059801211960243, 1.0, 1.0, 1.0]], [[0.03331980666396134, 1.0, 1.0, 1.0], [0.015619803123960625, 1.0, 1.0, 1.0], [0.012999802599960522, 1.0, 1.0, 1.0], [0.006059801211960243, 1.0, 1.0, 1.0], [0.013239802647960531, 1.0, 1.0, 1.0]], [[0.015619803123960625, 1.0, 1.0, 1.0], [0.012999802599960522, 1.0, 1.0, 1.0], [0.006059801211960243, 1.0, 1.0, 1.0], [0.013239802647960531, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0]], [[0.012999802599960522, 1.0, 1.0, 1.0], [0.006059801211960243, 1.0, 1.0, 1.0], [0.013239802647960531, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0]], [[0.006059801211960243, 1.0, 1.0, 1.0], [0.013239802647960531, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.012659802531960508, 1.0, 1.0, 1.0]], [[0.013239802647960531, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.012659802531960508, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0]], [[0.0199998039999608, 1.0, 1.0, 1.0], [0.013639802727960549, 1.0, 1.0, 1.0], [0.012659802531960508, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0]], [[0.013639802727960549, 1.0, 1.0, 1.0], [0.012659802531960508, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.027999805599961118, 1.0, 1.0, 1.0]], [[0.012659802531960508, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.027999805599961118, 1.0, 1.0, 1.0], [0.0198998039799608, 1.0, 1.0, 1.0]], [[0.01369980273996055, 1.0, 1.0, 1.0], [0.01369980273996055, 1.0, 1.0, 1.0], [0.027999805599961118, 1.0, 1.0, 1.0], [0.0198998039799608, 1.0, 1.0, 1.0], [0.025179805035961008, 1.0, 1.0, 1.0]], [[0.01369980273996055, 1.0, 1.0, 1.0], [0.027999805599961118, 1.0, 1.0, 1.0], [0.0198998039799608, 1.0, 1.0, 1.0], [0.025179805035961008, 1.0, 1.0, 1.0], [0.01919980383996077, 1.0, 1.0, 1.0]], [[0.027999805599961118, 1.0, 1.0, 1.0], [0.0198998039799608, 1.0, 1.0, 1.0], [0.025179805035961008, 1.0, 1.0, 1.0], [0.01919980383996077, 1.0, 1.0, 1.0], [0.021119804223960845, 1.0, 1.0, 1.0]], [[0.0198998039799608, 1.0, 1.0, 1.0], [0.025179805035961008, 1.0, 1.0, 1.0], [0.01919980383996077, 1.0, 1.0, 1.0], [0.021119804223960845, 1.0, 1.0, 1.0], [0.01647980329596066, 1.0, 1.0, 1.0]], [[0.025179805035961008, 1.0, 1.0, 1.0], [0.01919980383996077, 1.0, 1.0, 1.0], [0.021119804223960845, 1.0, 1.0, 1.0], [0.01647980329596066, 1.0, 1.0, 1.0], [0.0066198013239602655, 1.0, 1.0, 1.0]], [[0.01919980383996077, 1.0, 1.0, 1.0], [0.021119804223960845, 1.0, 1.0, 1.0], [0.01647980329596066, 1.0, 1.0, 1.0], [0.0066198013239602655, 1.0, 1.0, 1.0], [0.01699980339996068, 1.0, 1.0, 1.0]], [[0.021119804223960845, 1.0, 1.0, 1.0], [0.01647980329596066, 1.0, 1.0, 1.0], [0.0066198013239602655, 1.0, 1.0, 1.0], [0.01699980339996068, 1.0, 1.0, 1.0], [0.0399398079879616, 1.0, 1.0, 1.0]], [[0.01647980329596066, 1.0, 1.0, 1.0], [0.0066198013239602655, 1.0, 1.0, 1.0], [0.01699980339996068, 1.0, 1.0, 1.0], [0.0399398079879616, 1.0, 1.0, 1.0], [0.014379802875960575, 1.0, 1.0, 1.0]], [[0.0066198013239602655, 1.0, 1.0, 1.0], [0.01699980339996068, 1.0, 1.0, 1.0], [0.0399398079879616, 1.0, 1.0, 1.0], [0.014379802875960575, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0]], [[0.01699980339996068, 1.0, 1.0, 1.0], [0.0399398079879616, 1.0, 1.0, 1.0], [0.014379802875960575, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0]], [[0.0399398079879616, 1.0, 1.0, 1.0], [0.014379802875960575, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.011379802275960456, 1.0, 1.0, 1.0]], [[0.014379802875960575, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.011379802275960456, 1.0, 1.0, 1.0], [0.008419801683960337, 1.0, 1.0, 1.0]], [[0.017599803519960704, 1.0, 1.0, 1.0], [0.017599803519960704, 1.0, 1.0, 1.0], [0.011379802275960456, 1.0, 1.0, 1.0], [0.008419801683960337, 1.0, 1.0, 1.0], [0.011879802375960476, 1.0, 1.0, 1.0]], [[0.017599803519960704, 1.0, 1.0, 1.0], [0.011379802275960456, 1.0, 1.0, 1.0], [0.008419801683960337, 1.0, 1.0, 1.0], [0.011879802375960476, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0]], [[0.011379802275960456, 1.0, 1.0, 1.0], [0.008419801683960337, 1.0, 1.0, 1.0], [0.011879802375960476, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0]], [[0.008419801683960337, 1.0, 1.0, 1.0], [0.011879802375960476, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.010639802127960427, 1.0, 1.0, 1.0]], [[0.011879802375960476, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.010639802127960427, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0]], [[0.01149980229996046, 1.0, 1.0, 1.0], [0.01149980229996046, 1.0, 1.0, 1.0], [0.010639802127960427, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.016199803239960647, 1.0, 1.0, 1.0]], [[0.01149980229996046, 1.0, 1.0, 1.0], [0.010639802127960427, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.016199803239960647, 1.0, 1.0, 1.0], [0.024399804879960976, 1.0, 1.0, 1.0]], [[0.010639802127960427, 1.0, 1.0, 1.0], [0.0274598054919611, 1.0, 1.0, 1.0], [0.016199803239960647, 1.0, 1.0, 1.0], [0.024399804879960976, 1.0, 1.0, 1.0], [0.021039804207960842, 1.0, 1.0, 1.0]], [[0.0274598054919611, 1.0, 1.0, 1.0], [0.016199803239960647, 1.0, 1.0, 1.0], [0.024399804879960976, 1.0, 1.0, 1.0], [0.021039804207960842, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0]], [[0.016199803239960647, 1.0, 1.0, 1.0], [0.024399804879960976, 1.0, 1.0, 1.0], [0.021039804207960842, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.018099803619960726, 1.0, 1.0, 1.0]], [[0.024399804879960976, 1.0, 1.0, 1.0], [0.021039804207960842, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.018099803619960726, 1.0, 1.0, 1.0], [0.028379805675961132, 1.0, 1.0, 1.0]], [[0.021039804207960842, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.018099803619960726, 1.0, 1.0, 1.0], [0.028379805675961132, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0]], [[0.026279805255961054, 1.0, 1.0, 1.0], [0.018099803619960726, 1.0, 1.0, 1.0], [0.028379805675961132, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.022739804547960908, 1.0, 1.0, 1.0]], [[0.018099803619960726, 1.0, 1.0, 1.0], [0.028379805675961132, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.022739804547960908, 1.0, 1.0, 1.0], [0.024439804887960975, 1.0, 1.0, 1.0]], [[0.028379805675961132, 1.0, 1.0, 1.0], [0.030879806175961238, 1.0, 1.0, 1.0], [0.022739804547960908, 1.0, 1.0, 1.0], [0.024439804887960975, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.030879806175961238, 1.0, 1.0, 1.0], [0.022739804547960908, 1.0, 1.0, 1.0], [0.024439804887960975, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0]], [[0.022739804547960908, 1.0, 1.0, 1.0], [0.024439804887960975, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.028159805631961132, 1.0, 1.0, 1.0]], [[0.024439804887960975, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.028159805631961132, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.018839803767960756, 1.0, 1.0, 1.0], [0.028159805631961132, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0]], [[0.018839803767960756, 1.0, 1.0, 1.0], [0.028159805631961132, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.008179801635960328, 1.0, 1.0, 1.0]], [[0.028159805631961132, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.008179801635960328, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0]], [[0.030439806087961218, 1.0, 1.0, 1.0], [0.030439806087961218, 1.0, 1.0, 1.0], [0.008179801635960328, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [0.033039806607961325, 1.0, 1.0, 1.0]], [[0.030439806087961218, 1.0, 1.0, 1.0], [0.008179801635960328, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [0.033039806607961325, 1.0, 1.0, 1.0], [0.021779804355960868, 1.0, 1.0, 1.0]], [[0.008179801635960328, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [0.033039806607961325, 1.0, 1.0, 1.0], [0.021779804355960868, 1.0, 1.0, 1.0], [0.02699980539996108, 1.0, 1.0, 1.0]], [[0.0017998003599600722, 1.0, 1.0, 1.0], [0.033039806607961325, 1.0, 1.0, 1.0], [0.021779804355960868, 1.0, 1.0, 1.0], [0.02699980539996108, 1.0, 1.0, 1.0], [0.01321800264360053, 1.0, 1.0, 1.0]], [[0.033039806607961325, 1.0, 1.0, 1.0], [0.021779804355960868, 1.0, 1.0, 1.0], [0.02699980539996108, 1.0, 1.0, 1.0], [0.01321800264360053, 1.0, 1.0, 1.0], [0.0049198009839601965, 1.0, 1.0, 1.0]], [[0.021779804355960868, 1.0, 1.0, 1.0], [0.02699980539996108, 1.0, 1.0, 1.0], [0.01321800264360053, 1.0, 1.0, 1.0], [0.0049198009839601965, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0]], [[0.02699980539996108, 1.0, 1.0, 1.0], [0.01321800264360053, 1.0, 1.0, 1.0], [0.0049198009839601965, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0]], [[0.01321800264360053, 1.0, 1.0, 1.0], [0.0049198009839601965, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0]], [[0.0049198009839601965, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0]], [[0.025399805079961014, 1.0, 1.0, 1.0], [0.025399805079961014, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.025679805135961027, 1.0, 1.0, 1.0]], [[0.025399805079961014, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.025679805135961027, 1.0, 1.0, 1.0], [0.017099803419960685, 1.0, 1.0, 1.0]], [[0.021599804319960864, 1.0, 1.0, 1.0], [0.021599804319960864, 1.0, 1.0, 1.0], [0.025679805135961027, 1.0, 1.0, 1.0], [0.017099803419960685, 1.0, 1.0, 1.0], [0.02759980551996111, 1.0, 1.0, 1.0]], [[0.021599804319960864, 1.0, 1.0, 1.0], [0.025679805135961027, 1.0, 1.0, 1.0], [0.017099803419960685, 1.0, 1.0, 1.0], [0.02759980551996111, 1.0, 1.0, 1.0], [0.02073980414796083, 1.0, 1.0, 1.0]], [[0.025679805135961027, 1.0, 1.0, 1.0], [0.017099803419960685, 1.0, 1.0, 1.0], [0.02759980551996111, 1.0, 1.0, 1.0], [0.02073980414796083, 1.0, 1.0, 1.0], [0.025619805123961024, 1.0, 1.0, 1.0]], [[0.017099803419960685, 1.0, 1.0, 1.0], [0.02759980551996111, 1.0, 1.0, 1.0], [0.02073980414796083, 1.0, 1.0, 1.0], [0.025619805123961024, 1.0, 1.0, 1.0], [0.02597980519596104, 1.0, 1.0, 1.0]], [[0.02759980551996111, 1.0, 1.0, 1.0], [0.02073980414796083, 1.0, 1.0, 1.0], [0.025619805123961024, 1.0, 1.0, 1.0], [0.02597980519596104, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0]], [[0.02073980414796083, 1.0, 1.0, 1.0], [0.025619805123961024, 1.0, 1.0, 1.0], [0.02597980519596104, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0]], [[0.025619805123961024, 1.0, 1.0, 1.0], [0.02597980519596104, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0]], [[0.02597980519596104, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.04111980822396165, 1.0, 1.0, 1.0]], [[0.039999807999961605, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.04111980822396165, 1.0, 1.0, 1.0], [0.041279808255961656, 1.0, 1.0, 1.0]], [[0.02693980538796108, 1.0, 1.0, 1.0], [0.02693980538796108, 1.0, 1.0, 1.0], [0.04111980822396165, 1.0, 1.0, 1.0], [0.041279808255961656, 1.0, 1.0, 1.0], [0.010799802159960431, 1.0, 1.0, 1.0]], [[0.02693980538796108, 1.0, 1.0, 1.0], [0.04111980822396165, 1.0, 1.0, 1.0], [0.041279808255961656, 1.0, 1.0, 1.0], [0.010799802159960431, 1.0, 1.0, 1.0], [0.004018200803640161, 1.0, 1.0, 1.0]], [[0.04111980822396165, 1.0, 1.0, 1.0], [0.041279808255961656, 1.0, 1.0, 1.0], [0.010799802159960431, 1.0, 1.0, 1.0], [0.004018200803640161, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0]], [[0.041279808255961656, 1.0, 1.0, 1.0], [0.010799802159960431, 1.0, 1.0, 1.0], [0.004018200803640161, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.03453980690796138, 1.0, 1.0, 1.0]], [[0.010799802159960431, 1.0, 1.0, 1.0], [0.004018200803640161, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.03453980690796138, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0]], [[0.004018200803640161, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.03453980690796138, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0], [0.02321980464396093, 1.0, 1.0, 1.0]], [[0.0224998044999609, 1.0, 1.0, 1.0], [0.03453980690796138, 1.0, 1.0, 1.0], [0.03815980763196153, 1.0, 1.0, 1.0], [0.02321980464396093, 1.0, 1.0, 1.0], [0.0325598065119613, 1.0, 1.0, 1.0]], [[0.0005044001008800203, 1.0, 1.0, 1.0], [0.0017998003599600722, 1.0, 1.0, 1.0], [0.000399800079960016, 1.0, 1.0, 1.0], [0.0021998004399600888, 1.0, 1.0, 1.0], [0.005423601084720218, 1.0, 1.0, 1.0]], [[0.007173001434600287, 1.0, 1.0, 1.0], [0.006822001364400274, 1.0, 1.0, 1.0], [0.004177000835400168, 1.0, 1.0, 1.0], [0.007629001525800306, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0]], [[0.006822001364400274, 1.0, 1.0, 1.0], [0.004177000835400168, 1.0, 1.0, 1.0], [0.007629001525800306, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.023625004725000943, 1.0, 1.0, 1.0]], [[0.004177000835400168, 1.0, 1.0, 1.0], [0.007629001525800306, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.023625004725000943, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0]], [[0.015479803095960622, 1.0, 1.0, 1.0], [0.01829980365996073, 1.0, 1.0, 1.0], [0.016591803318360663, 1.0, 1.0, 1.0], [0.005392201078440215, 1.0, 1.0, 1.0], [0.009899801979960396, 1.0, 1.0, 1.0]], [[0.01829980365996073, 1.0, 1.0, 1.0], [0.016591803318360663, 1.0, 1.0, 1.0], [0.005392201078440215, 1.0, 1.0, 1.0], [0.009899801979960396, 1.0, 1.0, 1.0], [0.010574202114840423, 1.0, 1.0, 1.0]], [[0.016591803318360663, 1.0, 1.0, 1.0], [0.005392201078440215, 1.0, 1.0, 1.0], [0.009899801979960396, 1.0, 1.0, 1.0], [0.010574202114840423, 1.0, 1.0, 1.0], [0.01627260325452065, 1.0, 1.0, 1.0]], [[0.005392201078440215, 1.0, 1.0, 1.0], [0.009899801979960396, 1.0, 1.0, 1.0], [0.010574202114840423, 1.0, 1.0, 1.0], [0.01627260325452065, 1.0, 1.0, 1.0], [0.001599800319960064, 1.0, 1.0, 1.0]], [[0.08550381710076342, 1.0, 1.0, 1.0], [0.0066414013282802675, 1.0, 1.0, 1.0], [0.012777402555480512, 1.0, 1.0, 1.0], [0.0199998039999608, 1.0, 1.0, 1.0], [0.007002601400520282, 1.0, 1.0, 1.0]], [[0.002999800599960121, 1.0, 1.0, 1.0], [0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0]], [[0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0]], [[0.002459800491960099, 1.0, 1.0, 1.0], [0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.000399800079960016, 1.0, 1.0, 1.0]], [[0.002759800551960111, 1.0, 1.0, 1.0], [0.002459800491960099, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.000399800079960016, 1.0, 1.0, 1.0], [0.001999800399960081, 1.0, 1.0, 1.0]], [[0.002459800491960099, 1.0, 1.0, 1.0], [0.002999800599960121, 1.0, 1.0, 1.0], [0.000399800079960016, 1.0, 1.0, 1.0], [0.001999800399960081, 1.0, 1.0, 1.0], [0.001999800399960081, 1.0, 1.0, 1.0]], [[0.03615520723104145, 1.0, 1.0, 1.0], [0.001999800399960081, 1.0, 1.0, 0.0], [0.0015310003062000614, 1.0, 1.0, 1.0], [0.0025040005008001003, 1.0, 1.0, 1.0], [0.1645950329190066, 1.0, 1.0, 1.0]], [[0.001999800399960081, 1.0, 1.0, 0.0], [0.0015310003062000614, 1.0, 1.0, 1.0], [0.0025040005008001003, 1.0, 1.0, 1.0], [0.1645950329190066, 1.0, 1.0, 1.0], [0.008407001681400338, 1.0, 1.0, 1.0]], [[0.0021998004399600888, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.003999800799960161, 1.0, 0.0, 1.0], [0.000699800139960028, 1.0, 0.0, 1.0], [0.007319801463960294, 1.0, 0.0, 1.0]], [[0.005999801199960241, 1.0, 0.0, 1.0], [0.003999800799960161, 1.0, 0.0, 1.0], [0.000699800139960028, 1.0, 0.0, 1.0], [0.007319801463960294, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0]], [[0.003999800799960161, 1.0, 0.0, 1.0], [0.000699800139960028, 1.0, 0.0, 1.0], [0.007319801463960294, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.0048920009784001964, 1.0, 0.0, 1.0]], [[0.000699800139960028, 1.0, 0.0, 1.0], [0.007319801463960294, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.0048920009784001964, 1.0, 0.0, 1.0], [0.00398400079680016, 1.0, 0.0, 1.0]], [[0.007319801463960294, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.0048920009784001964, 1.0, 0.0, 1.0], [0.00398400079680016, 1.0, 0.0, 1.0], [0.005532201106440223, 1.0, 0.0, 1.0]], [[0.039999807999961605, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.07694741538948309, 1.0, 1.0, 1.0], [0.06419621283924258, 1.0, 1.0, 1.0], [0.08580241716048344, 1.0, 1.0, 1.0]], [[0.039999807999961605, 1.0, 1.0, 1.0], [0.07694741538948309, 1.0, 1.0, 1.0], [0.06419621283924258, 1.0, 1.0, 1.0], [0.08580241716048344, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0]], [[0.07694741538948309, 1.0, 1.0, 1.0], [0.06419621283924258, 1.0, 1.0, 1.0], [0.08580241716048344, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0]], [[0.06419621283924258, 1.0, 1.0, 1.0], [0.08580241716048344, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0]], [[0.08580241716048344, 1.0, 1.0, 1.0], [0.0299998059999612, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0]], [[0.0299998059999612, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0]], [[0.011139802227960445, 1.0, 1.0, 1.0], [0.011139802227960445, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0]], [[0.011139802227960445, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.026719805343961067, 1.0, 1.0, 1.0]], [[0.006319801263960254, 1.0, 1.0, 1.0], [0.006319801263960254, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.026719805343961067, 1.0, 1.0, 1.0], [0.02645980529196106, 1.0, 1.0, 1.0]], [[0.006319801263960254, 1.0, 1.0, 1.0], [0.026279805255961054, 1.0, 1.0, 1.0], [0.026719805343961067, 1.0, 1.0, 1.0], [0.02645980529196106, 1.0, 1.0, 1.0], [0.005084601016920204, 1.0, 1.0, 1.0]], [[0.026279805255961054, 1.0, 1.0, 1.0], [0.026719805343961067, 1.0, 1.0, 1.0], [0.02645980529196106, 1.0, 1.0, 1.0], [0.005084601016920204, 1.0, 1.0, 1.0], [0.02513980502796101, 1.0, 1.0, 1.0]], [[0.026719805343961067, 1.0, 1.0, 1.0], [0.02645980529196106, 1.0, 1.0, 1.0], [0.005084601016920204, 1.0, 1.0, 1.0], [0.02513980502796101, 1.0, 1.0, 1.0], [0.0174998034999607, 1.0, 1.0, 1.0]], [[0.02645980529196106, 1.0, 1.0, 1.0], [0.005084601016920204, 1.0, 1.0, 1.0], [0.02513980502796101, 1.0, 1.0, 1.0], [0.0174998034999607, 1.0, 1.0, 1.0], [0.011799802359960471, 1.0, 1.0, 1.0]], [[0.005084601016920204, 1.0, 1.0, 1.0], [0.02513980502796101, 1.0, 1.0, 1.0], [0.0174998034999607, 1.0, 1.0, 1.0], [0.011799802359960471, 1.0, 1.0, 1.0], [0.006939801387960278, 1.0, 1.0, 1.0]], [[0.02513980502796101, 1.0, 1.0, 1.0], [0.0174998034999607, 1.0, 1.0, 1.0], [0.011799802359960471, 1.0, 1.0, 1.0], [0.006939801387960278, 1.0, 1.0, 1.0], [0.017119803423960685, 1.0, 1.0, 1.0]], [[0.0174998034999607, 1.0, 1.0, 1.0], [0.011799802359960471, 1.0, 1.0, 1.0], [0.006939801387960278, 1.0, 1.0, 1.0], [0.017119803423960685, 1.0, 1.0, 1.0], [0.025539805107961024, 1.0, 1.0, 1.0]], [[0.011799802359960471, 1.0, 1.0, 1.0], [0.006939801387960278, 1.0, 1.0, 1.0], [0.017119803423960685, 1.0, 1.0, 1.0], [0.025539805107961024, 1.0, 1.0, 1.0], [0.01771980354396071, 1.0, 1.0, 1.0]], [[0.006939801387960278, 1.0, 1.0, 1.0], [0.017119803423960685, 1.0, 1.0, 1.0], [0.025539805107961024, 1.0, 1.0, 1.0], [0.01771980354396071, 1.0, 1.0, 1.0], [0.027819805563961117, 1.0, 1.0, 1.0]], [[0.004481400896280179, 1.0, 0.0, 1.0], [0.001959800391960079, 1.0, 0.0, 1.0], [0.009999801999960402, 1.0, 0.0, 1.0], [0.00013980002796000558, 1.0, 0.0, 1.0], [0.00047100009420001884, 1.0, 0.0, 1.0]], [[0.0023398004679600947, 1.0, 0.0, 1.0], [0.011938002387600479, 1.0, 0.0, 1.0], [0.008809801761960353, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.011596002319200464, 1.0, 0.0, 1.0]], [[0.011938002387600479, 1.0, 0.0, 1.0], [0.008809801761960353, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.011596002319200464, 1.0, 0.0, 1.0], [0.0018734003746800755, 1.0, 0.0, 1.0]], [[0.008809801761960353, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.011596002319200464, 1.0, 0.0, 1.0], [0.0018734003746800755, 1.0, 0.0, 1.0], [0.023999804799960958, 1.0, 0.0, 1.0]], [[0.004399800879960177, 1.0, 0.0, 1.0], [0.011596002319200464, 1.0, 0.0, 1.0], [0.0018734003746800755, 1.0, 0.0, 1.0], [0.023999804799960958, 1.0, 0.0, 1.0], [0.004159800831960167, 1.0, 0.0, 1.0]], [[0.011596002319200464, 1.0, 0.0, 1.0], [0.0018734003746800755, 1.0, 0.0, 1.0], [0.023999804799960958, 1.0, 0.0, 1.0], [0.004159800831960167, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0]], [[0.0018734003746800755, 1.0, 0.0, 1.0], [0.023999804799960958, 1.0, 0.0, 1.0], [0.004159800831960167, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.003059800611960123, 1.0, 0.0, 1.0]], [[0.023999804799960958, 1.0, 0.0, 1.0], [0.004159800831960167, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.003059800611960123, 1.0, 0.0, 1.0], [0.007915801583160319, 1.0, 0.0, 1.0]], [[0.004159800831960167, 1.0, 0.0, 1.0], [0.005999801199960241, 1.0, 0.0, 1.0], [0.003059800611960123, 1.0, 0.0, 1.0], [0.007915801583160319, 1.0, 0.0, 1.0], [0.7999999599999921, 1.0, 0.0, 1.0]], [[0.005999801199960241, 1.0, 0.0, 1.0], [0.003059800611960123, 1.0, 0.0, 1.0], [0.007915801583160319, 1.0, 0.0, 1.0], [0.7999999599999921, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0]], [[0.003059800611960123, 1.0, 0.0, 1.0], [0.007915801583160319, 1.0, 0.0, 1.0], [0.7999999599999921, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.003999800799960161, 1.0, 0.0, 1.0]], [[0.007915801583160319, 1.0, 0.0, 1.0], [0.7999999599999921, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.003999800799960161, 1.0, 0.0, 1.0], [0.0004998000999600201, 1.0, 0.0, 1.0]], [[0.7999999599999921, 1.0, 0.0, 1.0], [0.004399800879960177, 1.0, 0.0, 1.0], [0.003999800799960161, 1.0, 0.0, 1.0], [0.0004998000999600201, 1.0, 0.0, 1.0], [0.0009998001999600402, 1.0, 0.0, 1.0]], [[0.025619805123961024, 1.0, 1.0, 1.0], [0.010979802195960441, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.13843722768744554, 1.0, 1.0, 1.0], [0.056220611244122254, 1.0, 1.0, 1.0]], [[0.010979802195960441, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.13843722768744554, 1.0, 1.0, 1.0], [0.056220611244122254, 1.0, 1.0, 1.0], [0.02191300438260088, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.13843722768744554, 1.0, 1.0, 1.0], [0.056220611244122254, 1.0, 1.0, 1.0], [0.02191300438260088, 1.0, 1.0, 1.0], [0.09670221934044387, 1.0, 1.0, 1.0]], [[0.13843722768744554, 1.0, 1.0, 1.0], [0.056220611244122254, 1.0, 1.0, 1.0], [0.02191300438260088, 1.0, 1.0, 1.0], [0.09670221934044387, 1.0, 1.0, 1.0], [0.2096018419203684, 1.0, 1.0, 1.0]], [[0.056220611244122254, 1.0, 1.0, 1.0], [0.02191300438260088, 1.0, 1.0, 1.0], [0.09670221934044387, 1.0, 1.0, 1.0], [0.2096018419203684, 1.0, 1.0, 1.0], [0.14742322948464592, 1.0, 1.0, 1.0]], [[0.02191300438260088, 1.0, 1.0, 1.0], [0.09670221934044387, 1.0, 1.0, 1.0], [0.2096018419203684, 1.0, 1.0, 1.0], [0.14742322948464592, 1.0, 1.0, 1.0], [0.7673579534715909, 1.0, 1.0, 1.0]], [[0.09670221934044387, 1.0, 1.0, 1.0], [0.2096018419203684, 1.0, 1.0, 1.0], [0.14742322948464592, 1.0, 1.0, 1.0], [0.7673579534715909, 1.0, 1.0, 1.0], [0.05529981105996221, 1.0, 1.0, 1.0]], [[0.2096018419203684, 1.0, 1.0, 1.0], [0.14742322948464592, 1.0, 1.0, 1.0], [0.7673579534715909, 1.0, 1.0, 1.0], [0.05529981105996221, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.14742322948464592, 1.0, 1.0, 1.0], [0.7673579534715909, 1.0, 1.0, 1.0], [0.05529981105996221, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0]], [[0.7673579534715909, 1.0, 1.0, 1.0], [0.05529981105996221, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.3051138610227723, 1.0, 1.0, 1.0]], [[0.05529981105996221, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.3051138610227723, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.3051138610227723, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0]], [[0.039999807999961605, 1.0, 1.0, 1.0], [0.3051138610227723, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0]], [[0.3051138610227723, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.05999981199996241, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.20068784013756805, 1.0, 1.0, 1.0]], [[0.05999981199996241, 1.0, 1.0, 1.0], [0.013879802775960556, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.20068784013756805, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0]], [[0.013879802775960556, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.20068784013756805, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0]], [[0.07999981599996321, 1.0, 1.0, 1.0], [0.20068784013756805, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0]], [[0.20068784013756805, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0]], [[0.199999839999968, 1.0, 1.0, 1.0], [0.3999998799999761, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0]], [[0.3999998799999761, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0]], [[0.199999839999968, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0], [0.4679918935983788, 1.0, 1.0, 1.0]], [[0.07999981599996321, 1.0, 1.0, 1.0], [0.07999981599996321, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0], [0.4679918935983788, 1.0, 1.0, 1.0], [0.1199998239999648, 1.0, 1.0, 1.0]], [[0.07999981599996321, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0], [0.4679918935983788, 1.0, 1.0, 1.0], [0.1199998239999648, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0]], [[0.09999981999996402, 1.0, 1.0, 1.0], [0.4679918935983788, 1.0, 1.0, 1.0], [0.1199998239999648, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0]], [[0.4679918935983788, 1.0, 1.0, 1.0], [0.1199998239999648, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.0045998009199601855, 1.0, 1.0, 1.0]], [[0.1199998239999648, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.0045998009199601855, 1.0, 1.0, 1.0], [0.005099801019960205, 1.0, 1.0, 1.0]], [[0.25999985199997044, 1.0, 1.0, 1.0], [0.25999985199997044, 1.0, 1.0, 1.0], [0.0045998009199601855, 1.0, 1.0, 1.0], [0.005099801019960205, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0]], [[0.25999985199997044, 1.0, 1.0, 1.0], [0.0045998009199601855, 1.0, 1.0, 1.0], [0.005099801019960205, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0], [0.10753602150720433, 1.0, 1.0, 1.0]], [[0.0045998009199601855, 1.0, 1.0, 1.0], [0.005099801019960205, 1.0, 1.0, 1.0], [0.09999981999996402, 1.0, 1.0, 1.0], [0.10753602150720433, 1.0, 1.0, 1.0], [0.04879980975996195, 1.0, 1.0, 1.0]], [[0.0199998039999608, 1.0, 1.0, 1.0], [0.19296723859344772, 1.0, 1.0, 1.0], [0.014279802855960573, 1.0, 1.0, 1.0], [0.007206001441200289, 1.0, 1.0, 1.0], [0.004819800963960194, 1.0, 1.0, 1.0]], [[0.19296723859344772, 1.0, 1.0, 1.0], [0.014279802855960573, 1.0, 1.0, 1.0], [0.007206001441200289, 1.0, 1.0, 1.0], [0.004819800963960194, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0]], [[0.014279802855960573, 1.0, 1.0, 1.0], [0.007206001441200289, 1.0, 1.0, 1.0], [0.004819800963960194, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0]], [[0.007206001441200289, 1.0, 1.0, 1.0], [0.004819800963960194, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0]], [[0.004819800963960194, 1.0, 1.0, 1.0], [0.039999807999961605, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0]], [[0.039999807999961605, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0]], [[0.005999801199960241, 1.0, 1.0, 1.0], [0.005999801199960241, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0]], [[0.005999801199960241, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.02130720426144085, 1.0, 1.0, 1.0]], [[0.03199980639996128, 1.0, 1.0, 1.0], [0.03199980639996128, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.02130720426144085, 1.0, 1.0, 1.0], [0.0044178008835601785, 1.0, 1.0, 1.0]], [[0.03199980639996128, 1.0, 1.0, 1.0], [0.023999804799960958, 1.0, 1.0, 1.0], [0.02130720426144085, 1.0, 1.0, 1.0], [0.0044178008835601785, 1.0, 1.0, 1.0], [0.0074248014849602985, 1.0, 1.0, 1.0]], [[0.023999804799960958, 1.0, 1.0, 1.0], [0.02130720426144085, 1.0, 1.0, 1.0], [0.0044178008835601785, 1.0, 1.0, 1.0], [0.0074248014849602985, 1.0, 1.0, 1.0], [0.0010518002103600422, 1.0, 1.0, 1.0]], [[0.02130720426144085, 1.0, 1.0, 1.0], [0.0044178008835601785, 1.0, 1.0, 1.0], [0.0074248014849602985, 1.0, 1.0, 1.0], [0.0010518002103600422, 1.0, 1.0, 1.0], [0.0031868006373601283, 1.0, 1.0, 1.0]], [[0.0044178008835601785, 1.0, 1.0, 1.0], [0.0074248014849602985, 1.0, 1.0, 1.0], [0.0010518002103600422, 1.0, 1.0, 1.0], [0.0031868006373601283, 1.0, 1.0, 1.0], [0.02019980403996081, 1.0, 1.0, 1.0]], [[0.0074248014849602985, 1.0, 1.0, 1.0], [0.0010518002103600422, 1.0, 1.0, 1.0], [0.0031868006373601283, 1.0, 1.0, 1.0], [0.02019980403996081, 1.0, 1.0, 1.0], [0.012159802431960487, 1.0, 1.0, 1.0]], [[0.0010518002103600422, 1.0, 1.0, 1.0], [0.0031868006373601283, 1.0, 1.0, 1.0], [0.02019980403996081, 1.0, 1.0, 1.0], [0.012159802431960487, 1.0, 1.0, 1.0], [0.04301980860396172, 1.0, 1.0, 1.0]], [[0.0031868006373601283, 1.0, 1.0, 1.0], [0.02019980403996081, 1.0, 1.0, 1.0], [0.012159802431960487, 1.0, 1.0, 1.0], [0.04301980860396172, 1.0, 1.0, 1.0], [0.019079803815960764, 1.0, 1.0, 1.0]], [[0.02019980403996081, 1.0, 1.0, 1.0], [0.012159802431960487, 1.0, 1.0, 1.0], [0.04301980860396172, 1.0, 1.0, 1.0], [0.019079803815960764, 1.0, 1.0, 1.0], [0.020769804153960836, 1.0, 1.0, 1.0]], [[0.012159802431960487, 1.0, 1.0, 1.0], [0.04301980860396172, 1.0, 1.0, 1.0], [0.019079803815960764, 1.0, 1.0, 1.0], [0.020769804153960836, 1.0, 1.0, 1.0], [0.008187801637560329, 1.0, 1.0, 1.0]], [[0.04301980860396172, 1.0, 1.0, 1.0], [0.019079803815960764, 1.0, 1.0, 1.0], [0.020769804153960836, 1.0, 1.0, 1.0], [0.008187801637560329, 1.0, 1.0, 1.0], [0.029359805871961176, 1.0, 1.0, 1.0]], [[0.019079803815960764, 1.0, 1.0, 1.0], [0.020769804153960836, 1.0, 1.0, 1.0], [0.008187801637560329, 1.0, 1.0, 1.0], [0.029359805871961176, 1.0, 1.0, 1.0], [0.01909620381924076, 1.0, 1.0, 1.0]], [[0.020769804153960836, 1.0, 1.0, 1.0], [0.008187801637560329, 1.0, 1.0, 1.0], [0.029359805871961176, 1.0, 1.0, 1.0], [0.01909620381924076, 1.0, 1.0, 1.0], [0.004939800987960197, 1.0, 1.0, 1.0]], [[0.008187801637560329, 1.0, 1.0, 1.0], [0.029359805871961176, 1.0, 1.0, 1.0], [0.01909620381924076, 1.0, 1.0, 1.0], [0.004939800987960197, 1.0, 1.0, 1.0], [0.0037998007599601524, 1.0, 1.0, 1.0]], [[0.029359805871961176, 1.0, 1.0, 1.0], [0.01909620381924076, 1.0, 1.0, 1.0], [0.004939800987960197, 1.0, 1.0, 1.0], [0.0037998007599601524, 1.0, 1.0, 1.0], [0.020039804007960803, 1.0, 1.0, 1.0]], [[0.01909620381924076, 1.0, 1.0, 1.0], [0.004939800987960197, 1.0, 1.0, 1.0], [0.0037998007599601524, 1.0, 1.0, 1.0], [0.020039804007960803, 1.0, 1.0, 1.0], [0.013079802615960524, 1.0, 1.0, 1.0]], [[0.004939800987960197, 1.0, 1.0, 1.0], [0.0037998007599601524, 1.0, 1.0, 1.0], [0.020039804007960803, 1.0, 1.0, 1.0], [0.013079802615960524, 1.0, 1.0, 1.0], [0.03163980632796127, 1.0, 1.0, 1.0]], [[0.0037998007599601524, 1.0, 1.0, 1.0], [0.020039804007960803, 1.0, 1.0, 1.0], [0.013079802615960524, 1.0, 1.0, 1.0], [0.03163980632796127, 1.0, 1.0, 1.0], [0.033659806731961346, 1.0, 1.0, 1.0]], [[0.020039804007960803, 1.0, 1.0, 1.0], [0.013079802615960524, 1.0, 1.0, 1.0], [0.03163980632796127, 1.0, 1.0, 1.0], [0.033659806731961346, 1.0, 1.0, 1.0], [0.016971203394240682, 1.0, 1.0, 1.0]], [[0.013079802615960524, 1.0, 1.0, 1.0], [0.03163980632796127, 1.0, 1.0, 1.0], [0.033659806731961346, 1.0, 1.0, 1.0], [0.016971203394240682, 1.0, 1.0, 1.0], [0.032923806584761316, 1.0, 1.0, 1.0]], [[0.03163980632796127, 1.0, 1.0, 1.0], [0.033659806731961346, 1.0, 1.0, 1.0], [0.016971203394240682, 1.0, 1.0, 1.0], [0.032923806584761316, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0]], [[0.033659806731961346, 1.0, 1.0, 1.0], [0.016971203394240682, 1.0, 1.0, 1.0], [0.032923806584761316, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.014839802967960596, 1.0, 1.0, 1.0]], [[0.016971203394240682, 1.0, 1.0, 1.0], [0.032923806584761316, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.014839802967960596, 1.0, 1.0, 1.0], [0.03125980625196125, 1.0, 1.0, 1.0]], [[0.032923806584761316, 1.0, 1.0, 1.0], [0.030179806035961213, 1.0, 1.0, 1.0], [0.014839802967960596, 1.0, 1.0, 1.0], [0.03125980625196125, 1.0, 1.0, 1.0], [0.020419804083960817, 1.0, 1.0, 1.0]], [[0.030179806035961213, 1.0, 1.0, 1.0], [0.014839802967960596, 1.0, 1.0, 1.0], [0.03125980625196125, 1.0, 1.0, 1.0], [0.020419804083960817, 1.0, 1.0, 1.0], [0.01931980386396077, 1.0, 1.0, 1.0]], [[0.014839802967960596, 1.0, 1.0, 1.0], [0.03125980625196125, 1.0, 1.0, 1.0], [0.020419804083960817, 1.0, 1.0, 1.0], [0.01931980386396077, 1.0, 1.0, 1.0], [0.025259805051961008, 1.0, 1.0, 1.0]], [[0.03125980625196125, 1.0, 1.0, 1.0], [0.020419804083960817, 1.0, 1.0, 1.0], [0.01931980386396077, 1.0, 1.0, 1.0], [0.025259805051961008, 1.0, 1.0, 1.0], [0.0274398054879611, 1.0, 1.0, 1.0]], [[0.020419804083960817, 1.0, 1.0, 1.0], [0.01931980386396077, 1.0, 1.0, 1.0], [0.025259805051961008, 1.0, 1.0, 1.0], [0.0274398054879611, 1.0, 1.0, 1.0], [0.04935980987196198, 1.0, 1.0, 1.0]], [[0.01931980386396077, 1.0, 1.0, 1.0], [0.025259805051961008, 1.0, 1.0, 1.0], [0.0274398054879611, 1.0, 1.0, 1.0], [0.04935980987196198, 1.0, 1.0, 1.0], [0.0053598010719602155, 1.0, 1.0, 1.0]], [[0.025259805051961008, 1.0, 1.0, 1.0], [0.0274398054879611, 1.0, 1.0, 1.0], [0.04935980987196198, 1.0, 1.0, 1.0], [0.0053598010719602155, 1.0, 1.0, 1.0], [0.003843200768640153, 1.0, 1.0, 1.0]], [[0.0274398054879611, 1.0, 1.0, 1.0], [0.04935980987196198, 1.0, 1.0, 1.0], [0.0053598010719602155, 1.0, 1.0, 1.0], [0.003843200768640153, 1.0, 1.0, 1.0], [0.02217980443596089, 1.0, 1.0, 1.0]], [[0.04935980987196198, 1.0, 1.0, 1.0], [0.0053598010719602155, 1.0, 1.0, 1.0], [0.003843200768640153, 1.0, 1.0, 1.0], [0.02217980443596089, 1.0, 1.0, 1.0], [0.01847980369596074, 1.0, 1.0, 1.0]], [[0.0053598010719602155, 1.0, 1.0, 1.0], [0.003843200768640153, 1.0, 1.0, 1.0], [0.02217980443596089, 1.0, 1.0, 1.0], [0.01847980369596074, 1.0, 1.0, 1.0], [0.02151980430396086, 1.0, 1.0, 1.0]], [[0.003843200768640153, 1.0, 1.0, 1.0], [0.02217980443596089, 1.0, 1.0, 1.0], [0.01847980369596074, 1.0, 1.0, 1.0], [0.02151980430396086, 1.0, 1.0, 1.0], [0.033439806687961336, 1.0, 1.0, 1.0]], [[0.02217980443596089, 1.0, 1.0, 1.0], [0.01847980369596074, 1.0, 1.0, 1.0], [0.02151980430396086, 1.0, 1.0, 1.0], [0.033439806687961336, 1.0, 1.0, 1.0], [0.12612342522468506, 1.0, 1.0, 1.0]], [[0.01847980369596074, 1.0, 1.0, 1.0], [0.02151980430396086, 1.0, 1.0, 1.0], [0.033439806687961336, 1.0, 1.0, 1.0], [0.12612342522468506, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0]], [[0.02151980430396086, 1.0, 1.0, 1.0], [0.033439806687961336, 1.0, 1.0, 1.0], [0.12612342522468506, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0]], [[0.033439806687961336, 1.0, 1.0, 1.0], [0.12612342522468506, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.002757000551400111, 1.0, 1.0, 1.0]], [[0.12612342522468506, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.002757000551400111, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0]], [[0.199999839999968, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.002757000551400111, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.005159801031960207, 1.0, 1.0, 1.0]], [[0.199999839999968, 1.0, 1.0, 1.0], [0.002757000551400111, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.005159801031960207, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0]], [[0.002757000551400111, 1.0, 1.0, 1.0], [0.009999801999960402, 1.0, 1.0, 1.0], [0.005159801031960207, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0]], [[0.009999801999960402, 1.0, 1.0, 1.0], [0.005159801031960207, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.02475100495020099, 1.0, 1.0, 1.0]], [[0.005159801031960207, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.02475100495020099, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0]], [[0.005539801107960223, 1.0, 1.0, 1.0], [0.005539801107960223, 1.0, 1.0, 1.0], [0.02475100495020099, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.21046184209236848, 1.0, 1.0, 1.0]], [[0.005539801107960223, 1.0, 1.0, 1.0], [0.02475100495020099, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.21046184209236848, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0]], [[0.02475100495020099, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.21046184209236848, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.011319802263960456, 1.0, 1.0, 1.0]], [[0.007999801599960322, 1.0, 1.0, 1.0], [0.21046184209236848, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.011319802263960456, 1.0, 1.0, 1.0], [0.035572207114441416, 1.0, 1.0, 1.0]], [[0.21046184209236848, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.011319802263960456, 1.0, 1.0, 1.0], [0.035572207114441416, 1.0, 1.0, 1.0], [0.02263980452796091, 1.0, 1.0, 1.0]], [[0.014179802835960568, 1.0, 1.0, 1.0], [0.011319802263960456, 1.0, 1.0, 1.0], [0.035572207114441416, 1.0, 1.0, 1.0], [0.02263980452796091, 1.0, 1.0, 1.0], [0.031379806275961264, 1.0, 1.0, 1.0]], [[0.011319802263960456, 1.0, 1.0, 1.0], [0.035572207114441416, 1.0, 1.0, 1.0], [0.02263980452796091, 1.0, 1.0, 1.0], [0.031379806275961264, 1.0, 1.0, 1.0], [0.013799802759960554, 1.0, 1.0, 1.0]], [[0.035572207114441416, 1.0, 1.0, 1.0], [0.02263980452796091, 1.0, 1.0, 1.0], [0.031379806275961264, 1.0, 1.0, 1.0], [0.013799802759960554, 1.0, 1.0, 1.0], [0.008059801611960323, 1.0, 1.0, 1.0]], [[0.02263980452796091, 1.0, 1.0, 1.0], [0.031379806275961264, 1.0, 1.0, 1.0], [0.013799802759960554, 1.0, 1.0, 1.0], [0.008059801611960323, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0]], [[0.031379806275961264, 1.0, 1.0, 1.0], [0.013799802759960554, 1.0, 1.0, 1.0], [0.008059801611960323, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.0013270002654000533, 1.0, 1.0, 1.0]], [[0.013799802759960554, 1.0, 1.0, 1.0], [0.008059801611960323, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.0013270002654000533, 1.0, 1.0, 1.0], [0.006762601352520271, 1.0, 1.0, 1.0]], [[0.008059801611960323, 1.0, 1.0, 1.0], [0.0224998044999609, 1.0, 1.0, 1.0], [0.0013270002654000533, 1.0, 1.0, 1.0], [0.006762601352520271, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0]], [[0.0224998044999609, 1.0, 1.0, 1.0], [0.0013270002654000533, 1.0, 1.0, 1.0], [0.006762601352520271, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.020399804079960816, 1.0, 1.0, 1.0]], [[0.0013270002654000533, 1.0, 1.0, 1.0], [0.006762601352520271, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.020399804079960816, 1.0, 1.0, 1.0], [0.014830002966000597, 1.0, 1.0, 1.0]], [[0.006762601352520271, 1.0, 1.0, 1.0], [0.014179802835960568, 1.0, 1.0, 1.0], [0.020399804079960816, 1.0, 1.0, 1.0], [0.014830002966000597, 1.0, 1.0, 1.0], [0.02227980445596089, 1.0, 1.0, 1.0]], [[0.014179802835960568, 1.0, 1.0, 1.0], [0.020399804079960816, 1.0, 1.0, 1.0], [0.014830002966000597, 1.0, 1.0, 1.0], [0.02227980445596089, 1.0, 1.0, 1.0], [0.04407980881596177, 1.0, 1.0, 1.0]], [[0.020399804079960816, 1.0, 1.0, 1.0], [0.014830002966000597, 1.0, 1.0, 1.0], [0.02227980445596089, 1.0, 1.0, 1.0], [0.04407980881596177, 1.0, 1.0, 1.0], [0.00447980089596018, 1.0, 1.0, 1.0]], [[0.014830002966000597, 1.0, 1.0, 1.0], [0.02227980445596089, 1.0, 1.0, 1.0], [0.04407980881596177, 1.0, 1.0, 1.0], [0.00447980089596018, 1.0, 1.0, 1.0], [0.011814202362840474, 1.0, 1.0, 1.0]], [[0.02227980445596089, 1.0, 1.0, 1.0], [0.04407980881596177, 1.0, 1.0, 1.0], [0.00447980089596018, 1.0, 1.0, 1.0], [0.011814202362840474, 1.0, 1.0, 1.0], [0.017028603405720686, 1.0, 1.0, 1.0]], [[0.04407980881596177, 1.0, 1.0, 1.0], [0.00447980089596018, 1.0, 1.0, 1.0], [0.011814202362840474, 1.0, 1.0, 1.0], [0.017028603405720686, 1.0, 1.0, 1.0], [0.013499802699960541, 1.0, 1.0, 1.0]], [[0.00447980089596018, 1.0, 1.0, 1.0], [0.011814202362840474, 1.0, 1.0, 1.0], [0.017028603405720686, 1.0, 1.0, 1.0], [0.013499802699960541, 1.0, 1.0, 1.0], [0.04121980824396165, 1.0, 1.0, 1.0]], [[0.011814202362840474, 1.0, 1.0, 1.0], [0.017028603405720686, 1.0, 1.0, 1.0], [0.013499802699960541, 1.0, 1.0, 1.0], [0.04121980824396165, 1.0, 1.0, 1.0], [0.0324998064999613, 1.0, 1.0, 1.0]], [[0.017028603405720686, 1.0, 1.0, 1.0], [0.013499802699960541, 1.0, 1.0, 1.0], [0.04121980824396165, 1.0, 1.0, 1.0], [0.0324998064999613, 1.0, 1.0, 1.0], [0.04199980839996168, 1.0, 1.0, 1.0]], [[0.013499802699960541, 1.0, 1.0, 1.0], [0.04121980824396165, 1.0, 1.0, 1.0], [0.0324998064999613, 1.0, 1.0, 1.0], [0.04199980839996168, 1.0, 1.0, 1.0], [0.0057144011428802285, 1.0, 1.0, 1.0]], [[0.04121980824396165, 1.0, 1.0, 1.0], [0.0324998064999613, 1.0, 1.0, 1.0], [0.04199980839996168, 1.0, 1.0, 1.0], [0.0057144011428802285, 1.0, 1.0, 1.0], [0.004436200887240178, 1.0, 1.0, 1.0]], [[0.0324998064999613, 1.0, 1.0, 1.0], [0.04199980839996168, 1.0, 1.0, 1.0], [0.0057144011428802285, 1.0, 1.0, 1.0], [0.004436200887240178, 1.0, 1.0, 1.0], [0.005112401022480204, 1.0, 1.0, 1.0]], [[0.04199980839996168, 1.0, 1.0, 1.0], [0.0057144011428802285, 1.0, 1.0, 1.0], [0.004436200887240178, 1.0, 1.0, 1.0], [0.005112401022480204, 1.0, 1.0, 1.0], [0.006103001220600246, 1.0, 1.0, 1.0]], [[0.0057144011428802285, 1.0, 1.0, 1.0], [0.004436200887240178, 1.0, 1.0, 1.0], [0.005112401022480204, 1.0, 1.0, 1.0], [0.006103001220600246, 1.0, 1.0, 1.0], [0.0035746007149201437, 1.0, 1.0, 1.0]], [[0.004436200887240178, 1.0, 1.0, 1.0], [0.005112401022480204, 1.0, 1.0, 1.0], [0.006103001220600246, 1.0, 1.0, 1.0], [0.0035746007149201437, 1.0, 1.0, 1.0], [0.009799801959960393, 1.0, 1.0, 1.0]], [[0.005112401022480204, 1.0, 1.0, 1.0], [0.006103001220600246, 1.0, 1.0, 1.0], [0.0035746007149201437, 1.0, 1.0, 1.0], [0.009799801959960393, 1.0, 1.0, 1.0], [0.0017136003427200687, 1.0, 1.0, 1.0]], [[0.006103001220600246, 1.0, 1.0, 1.0], [0.0035746007149201437, 1.0, 1.0, 1.0], [0.009799801959960393, 1.0, 1.0, 1.0], [0.0017136003427200687, 1.0, 1.0, 1.0], [0.009579801915960385, 1.0, 1.0, 1.0]], [[0.0035746007149201437, 1.0, 1.0, 1.0], [0.009799801959960393, 1.0, 1.0, 1.0], [0.0017136003427200687, 1.0, 1.0, 1.0], [0.009579801915960385, 1.0, 1.0, 1.0], [0.01792980358596072, 1.0, 1.0, 1.0]], [[0.009799801959960393, 1.0, 1.0, 1.0], [0.0017136003427200687, 1.0, 1.0, 1.0], [0.009579801915960385, 1.0, 1.0, 1.0], [0.01792980358596072, 1.0, 1.0, 1.0], [0.03541980708396142, 1.0, 1.0, 1.0]], [[0.0017136003427200687, 1.0, 1.0, 1.0], [0.009579801915960385, 1.0, 1.0, 1.0], [0.01792980358596072, 1.0, 1.0, 1.0], [0.03541980708396142, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0]], [[0.009579801915960385, 1.0, 1.0, 1.0], [0.01792980358596072, 1.0, 1.0, 1.0], [0.03541980708396142, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0]], [[0.01792980358596072, 1.0, 1.0, 1.0], [0.03541980708396142, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0]], [[0.03541980708396142, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0]], [[0.004639800927960186, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0]], [[0.004639800927960186, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0]], [[0.007999801599960322, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.011533202306640462, 1.0, 1.0, 1.0]], [[0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.011533202306640462, 1.0, 1.0, 1.0], [0.013597602719520546, 1.0, 1.0, 1.0]], [[0.009719801943960393, 1.0, 1.0, 1.0], [0.009719801943960393, 1.0, 1.0, 1.0], [0.011533202306640462, 1.0, 1.0, 1.0], [0.013597602719520546, 1.0, 1.0, 1.0], [0.010848402169680436, 1.0, 1.0, 1.0]], [[0.009719801943960393, 1.0, 1.0, 1.0], [0.011533202306640462, 1.0, 1.0, 1.0], [0.013597602719520546, 1.0, 1.0, 1.0], [0.010848402169680436, 1.0, 1.0, 1.0], [0.011004402200880442, 1.0, 1.0, 1.0]], [[0.011533202306640462, 1.0, 1.0, 1.0], [0.013597602719520546, 1.0, 1.0, 1.0], [0.010848402169680436, 1.0, 1.0, 1.0], [0.011004402200880442, 1.0, 1.0, 1.0], [0.010352402070480415, 1.0, 1.0, 1.0]], [[0.013597602719520546, 1.0, 1.0, 1.0], [0.010848402169680436, 1.0, 1.0, 1.0], [0.011004402200880442, 1.0, 1.0, 1.0], [0.010352402070480415, 1.0, 1.0, 1.0], [0.01047760209552042, 1.0, 1.0, 1.0]], [[0.010848402169680436, 1.0, 1.0, 1.0], [0.011004402200880442, 1.0, 1.0, 1.0], [0.010352402070480415, 1.0, 1.0, 1.0], [0.01047760209552042, 1.0, 1.0, 1.0], [0.016822603364520673, 1.0, 1.0, 1.0]], [[0.011004402200880442, 1.0, 1.0, 1.0], [0.010352402070480415, 1.0, 1.0, 1.0], [0.01047760209552042, 1.0, 1.0, 1.0], [0.016822603364520673, 1.0, 1.0, 1.0], [0.009037001807400365, 1.0, 1.0, 1.0]], [[0.010352402070480415, 1.0, 1.0, 1.0], [0.01047760209552042, 1.0, 1.0, 1.0], [0.016822603364520673, 1.0, 1.0, 1.0], [0.009037001807400365, 1.0, 1.0, 1.0], [0.003051400610280123, 1.0, 1.0, 1.0]], [[0.01047760209552042, 1.0, 1.0, 1.0], [0.016822603364520673, 1.0, 1.0, 1.0], [0.009037001807400365, 1.0, 1.0, 1.0], [0.003051400610280123, 1.0, 1.0, 1.0], [0.008359201671840335, 1.0, 1.0, 1.0]], [[0.016822603364520673, 1.0, 1.0, 1.0], [0.009037001807400365, 1.0, 1.0, 1.0], [0.003051400610280123, 1.0, 1.0, 1.0], [0.008359201671840335, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0]], [[0.009037001807400365, 1.0, 1.0, 1.0], [0.003051400610280123, 1.0, 1.0, 1.0], [0.008359201671840335, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07212621442524289, 1.0, 1.0, 1.0]], [[0.003051400610280123, 1.0, 1.0, 1.0], [0.008359201671840335, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07212621442524289, 1.0, 1.0, 1.0], [0.04919020983804197, 1.0, 1.0, 1.0]], [[0.008359201671840335, 1.0, 1.0, 1.0], [0.199999839999968, 1.0, 1.0, 1.0], [0.07212621442524289, 1.0, 1.0, 1.0], [0.04919020983804197, 1.0, 1.0, 1.0], [0.037333007466601495, 1.0, 1.0, 1.0]], [[0.199999839999968, 1.0, 1.0, 1.0], [0.07212621442524289, 1.0, 1.0, 1.0], [0.04919020983804197, 1.0, 1.0, 1.0], [0.037333007466601495, 1.0, 1.0, 1.0], [0.004579800915960185, 1.0, 1.0, 1.0]], [[0.07212621442524289, 1.0, 1.0, 1.0], [0.04919020983804197, 1.0, 1.0, 1.0], [0.037333007466601495, 1.0, 1.0, 1.0], [0.004579800915960185, 1.0, 1.0, 1.0], [0.0058798011759602364, 1.0, 1.0, 1.0]], [[0.04919020983804197, 1.0, 1.0, 1.0], [0.037333007466601495, 1.0, 1.0, 1.0], [0.004579800915960185, 1.0, 1.0, 1.0], [0.0058798011759602364, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0]], [[0.037333007466601495, 1.0, 1.0, 1.0], [0.004579800915960185, 1.0, 1.0, 1.0], [0.0058798011759602364, 1.0, 1.0, 1.0], [0.004639800927960186, 1.0, 1.0, 1.0], [0.007999801599960322, 1.0, 1.0, 1.0]], [[0.03159980631996127, 1.0, 1.0, 1.0], [0.023019804603960917, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0], [0.023589804717960943, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0]], [[0.023019804603960917, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0], [0.023589804717960943, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0]], [[0.03700980740196149, 1.0, 1.0, 1.0], [0.023589804717960943, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.002439800487960098, 1.0, 1.0, 1.0]], [[0.023589804717960943, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.002439800487960098, 1.0, 1.0, 1.0], [0.0020306004061200816, 1.0, 1.0, 1.0]], [[0.018059803611960724, 1.0, 1.0, 1.0], [0.018059803611960724, 1.0, 1.0, 1.0], [0.002439800487960098, 1.0, 1.0, 1.0], [0.0020306004061200816, 1.0, 1.0, 1.0], [0.05722441144488229, 1.0, 1.0, 1.0]], [[0.018059803611960724, 1.0, 1.0, 1.0], [0.002439800487960098, 1.0, 1.0, 1.0], [0.0020306004061200816, 1.0, 1.0, 1.0], [0.05722441144488229, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0]], [[0.002439800487960098, 1.0, 1.0, 1.0], [0.0020306004061200816, 1.0, 1.0, 1.0], [0.05722441144488229, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0]], [[0.0020306004061200816, 1.0, 1.0, 1.0], [0.05722441144488229, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.032349806469961294, 1.0, 1.0, 1.0]], [[0.05722441144488229, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.032349806469961294, 1.0, 1.0, 1.0], [0.023509804701960943, 1.0, 1.0, 1.0]], [[0.0049894009978802, 1.0, 1.0, 1.0], [0.0049894009978802, 1.0, 1.0, 1.0], [0.032349806469961294, 1.0, 1.0, 1.0], [0.023509804701960943, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0]], [[0.0049894009978802, 1.0, 1.0, 1.0], [0.032349806469961294, 1.0, 1.0, 1.0], [0.023509804701960943, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0], [0.01795980359196072, 1.0, 1.0, 1.0]], [[0.032349806469961294, 1.0, 1.0, 1.0], [0.023509804701960943, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0], [0.01795980359196072, 1.0, 1.0, 1.0], [0.02291980458396092, 1.0, 1.0, 1.0]], [[0.023509804701960943, 1.0, 1.0, 1.0], [0.03700980740196149, 1.0, 1.0, 1.0], [0.01795980359196072, 1.0, 1.0, 1.0], [0.02291980458396092, 1.0, 1.0, 1.0], [0.022559804511960904, 1.0, 1.0, 1.0]], [[0.03700980740196149, 1.0, 1.0, 1.0], [0.01795980359196072, 1.0, 1.0, 1.0], [0.02291980458396092, 1.0, 1.0, 1.0], [0.022559804511960904, 1.0, 1.0, 1.0], [0.02035980407196081, 1.0, 1.0, 1.0]], [[0.01795980359196072, 1.0, 1.0, 1.0], [0.02291980458396092, 1.0, 1.0, 1.0], [0.022559804511960904, 1.0, 1.0, 1.0], [0.02035980407196081, 1.0, 1.0, 1.0], [0.01627980325596065, 1.0, 1.0, 1.0]], [[0.02291980458396092, 1.0, 1.0, 1.0], [0.022559804511960904, 1.0, 1.0, 1.0], [0.02035980407196081, 1.0, 1.0, 1.0], [0.01627980325596065, 1.0, 1.0, 1.0], [0.019659803931960783, 1.0, 1.0, 1.0]], [[0.022559804511960904, 1.0, 1.0, 1.0], [0.02035980407196081, 1.0, 1.0, 1.0], [0.01627980325596065, 1.0, 1.0, 1.0], [0.019659803931960783, 1.0, 1.0, 1.0], [0.0048798009759601964, 1.0, 1.0, 1.0]], [[0.02035980407196081, 1.0, 1.0, 1.0], [0.01627980325596065, 1.0, 1.0, 1.0], [0.019659803931960783, 1.0, 1.0, 1.0], [0.0048798009759601964, 1.0, 1.0, 1.0], [0.004061200812240163, 1.0, 1.0, 1.0]], [[0.01627980325596065, 1.0, 1.0, 1.0], [0.019659803931960783, 1.0, 1.0, 1.0], [0.0048798009759601964, 1.0, 1.0, 1.0], [0.004061200812240163, 1.0, 1.0, 1.0], [0.057224211444842285, 1.0, 1.0, 1.0]], [[0.019659803931960783, 1.0, 1.0, 1.0], [0.0048798009759601964, 1.0, 1.0, 1.0], [0.004061200812240163, 1.0, 1.0, 1.0], [0.057224211444842285, 1.0, 1.0, 1.0], [0.003659800731960147, 1.0, 1.0, 1.0]], [[0.0048798009759601964, 1.0, 1.0, 1.0], [0.004061200812240163, 1.0, 1.0, 1.0], [0.057224211444842285, 1.0, 1.0, 1.0], [0.003659800731960147, 1.0, 1.0, 1.0], [0.00012180002436000488, 1.0, 1.0, 1.0]], [[0.004061200812240163, 1.0, 1.0, 1.0], [0.057224211444842285, 1.0, 1.0, 1.0], [0.003659800731960147, 1.0, 1.0, 1.0], [0.00012180002436000488, 1.0, 1.0, 1.0], [0.028799805759961158, 1.0, 1.0, 1.0]], [[0.057224211444842285, 1.0, 1.0, 1.0], [0.003659800731960147, 1.0, 1.0, 1.0], [0.00012180002436000488, 1.0, 1.0, 1.0], [0.028799805759961158, 1.0, 1.0, 1.0], [0.022939804587960917, 1.0, 1.0, 1.0]], [[0.003659800731960147, 1.0, 1.0, 1.0], [0.00012180002436000488, 1.0, 1.0, 1.0], [0.028799805759961158, 1.0, 1.0, 1.0], [0.022939804587960917, 1.0, 1.0, 1.0], [0.02044980408996082, 1.0, 1.0, 1.0]], [[0.00012180002436000488, 1.0, 1.0, 1.0], [0.028799805759961158, 1.0, 1.0, 1.0], [0.022939804587960917, 1.0, 1.0, 1.0], [0.02044980408996082, 1.0, 1.0, 1.0], [0.023849804769960955, 1.0, 1.0, 1.0]], [[0.028799805759961158, 1.0, 1.0, 1.0], [0.022939804587960917, 1.0, 1.0, 1.0], [0.02044980408996082, 1.0, 1.0, 1.0], [0.023849804769960955, 1.0, 1.0, 1.0], [0.023849804769960955, 1.0, 1.0, 1.0]], [[0.022939804587960917, 1.0, 1.0, 1.0], [0.02044980408996082, 1.0, 1.0, 1.0], [0.023849804769960955, 1.0, 1.0, 1.0], [0.023849804769960955, 1.0, 1.0, 1.0], [0.04153980830796167, 1.0, 1.0, 1.0]], [[0.013999802799960562, 1.0, 1.0, 1.0], [0.0009998001999600402, 1.0, 1.0, 1.0], [0.008996801799360361, 1.0, 1.0, 1.0], [0.1970298394059679, 1.0, 1.0, 1.0], [0.1097998219599644, 1.0, 1.0, 1.0]], [[0.0009998001999600402, 1.0, 1.0, 1.0], [0.008996801799360361, 1.0, 1.0, 1.0], [0.1970298394059679, 1.0, 1.0, 1.0], [0.1097998219599644, 1.0, 1.0, 1.0], [0.08637481727496346, 1.0, 1.0, 0.0]], [[0.008996801799360361, 1.0, 1.0, 1.0], [0.1970298394059679, 1.0, 1.0, 1.0], [0.1097998219599644, 1.0, 1.0, 1.0], [0.08637481727496346, 1.0, 1.0, 0.0], [0.0014998002999600602, 1.0, 1.0, 1.0]], [[0.1970298394059679, 1.0, 1.0, 1.0], [0.1097998219599644, 1.0, 1.0, 1.0], [0.08637481727496346, 1.0, 1.0, 0.0], [0.0014998002999600602, 1.0, 1.0, 1.0], [0.004593800918760185, 1.0, 1.0, 1.0]], [[0.1097998219599644, 1.0, 1.0, 1.0], [0.08637481727496346, 1.0, 1.0, 0.0], [0.0014998002999600602, 1.0, 1.0, 1.0], [0.004593800918760185, 1.0, 1.0, 1.0], [0.0010252002050400411, 1.0, 1.0, 1.0]], [[0.08637481727496346, 1.0, 1.0, 0.0], [0.0014998002999600602, 1.0, 1.0, 1.0], [0.004593800918760185, 1.0, 1.0, 1.0], [0.0010252002050400411, 1.0, 1.0, 1.0], [0.050062810012562006, 1.0, 1.0, 0.0]], [[0.0014998002999600602, 1.0, 1.0, 1.0], [0.004593800918760185, 1.0, 1.0, 1.0], [0.0010252002050400411, 1.0, 1.0, 1.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.050062810012562006, 1.0, 1.0, 0.0]], [[0.004593800918760185, 1.0, 1.0, 1.0], [0.0010252002050400411, 1.0, 1.0, 1.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.0007898001579600318, 1.0, 1.0, 0.0]], [[0.0010252002050400411, 1.0, 1.0, 1.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.0007898001579600318, 1.0, 1.0, 0.0], [0.0031458006291601266, 1.0, 1.0, 0.0]], [[0.050062810012562006, 1.0, 1.0, 0.0], [0.050062810012562006, 1.0, 1.0, 0.0], [0.0007898001579600318, 1.0, 1.0, 0.0], [0.0031458006291601266, 1.0, 1.0, 0.0], [0.0031458006291601266, 1.0, 1.0, 0.0]], [[0.050062810012562006, 1.0, 1.0, 0.0], [0.0007898001579600318, 1.0, 1.0, 0.0], [0.0031458006291601266, 1.0, 1.0, 0.0], [0.0031458006291601266, 1.0, 1.0, 0.0], [0.005999801199960241, 1.0, 1.0, 1.0]]]
[array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0]), array([0])]
There are 519 sequences with  273 users.
Current iteration: 0
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Model: "sequential_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_1 (LSTM)                (None, 5, 50)             11000     
_________________________________________________________________
lstm_2 (LSTM)                (None, 50)                20200     
_________________________________________________________________
dense_1 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
2019-10-10 12:06:48.024557: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Epoch 1/10
 - 1s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6887 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 2.802720069885254
Training Loss per epoch: [0.6886647979864914, 0.6886648060230727, 0.6886647919590554, 0.6886647852619042, 0.6886647832527589, 0.6886647939682007, 0.6886647879407647, 0.688664795977346, 0.6886647979864914, 0.6886648066927877]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 1
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_3 (LSTM)                (None, 5, 50)             11000     
_________________________________________________________________
lstm_4 (LSTM)                (None, 50)                20200     
_________________________________________________________________
dense_2 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6944 - acc: 0.1236 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 2.5583298206329346
Training Loss per epoch: [0.6944343045856176, 0.6944343615114019, 0.6944343427593789, 0.6944343775845645, 0.6944343521353904, 0.6944343514656752, 0.6944343963365877, 0.6944343635205472, 0.6944343755754192, 0.6944343454382392]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 2
Model: "sequential_3"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_5 (LSTM)                (None, 5, 50)             11000     
_________________________________________________________________
lstm_6 (LSTM)                (None, 50)                20200     
_________________________________________________________________
dense_3 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7136 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 3.0974061489105225
Training Loss per epoch: [0.7135714761326822, 0.7135714982332808, 0.71357146273838, 0.7135714607292347, 0.7135714547017987, 0.7135714593898045, 0.7135714640778102, 0.71357146273838, 0.7135714707749613, 0.7135714908664146]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 3
Model: "sequential_4"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_7 (LSTM)                (None, 5, 50)             11000     
_________________________________________________________________
lstm_8 (LSTM)                (None, 50)                20200     
_________________________________________________________________
dense_4 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6847 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 3.5275042057037354
Training Loss per epoch: [0.6846827308783371, 0.6846827395846334, 0.6846827462817846, 0.6846827456120694, 0.6846827355663428, 0.6846827308783371, 0.6846827677126681, 0.6846827121263139, 0.6846827462817846, 0.6846827101171686]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 4
Model: "sequential_5"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_9 (LSTM)                (None, 5, 50)             11000     
_________________________________________________________________
lstm_10 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_5 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6595 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 4.003515243530273
Training Loss per epoch: [0.6594779250327121, 0.6594779116384099, 0.6594779384270143, 0.6594779022623983, 0.659477948472741, 0.6594779658853338, 0.6594779169961308, 0.6594779357481538, 0.6594779390967294, 0.6594779605276129]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 5
Model: "sequential_6"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_11 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_12 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_6 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7457 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 4.590748310089111
Training Loss per epoch: [0.7456960510671808, 0.7456960376728786, 0.7456960082054138, 0.7456960323151578, 0.7456960316454426, 0.745696033654588, 0.7456960289665823, 0.7456960771860701, 0.745696033654588, 0.7456960356637333]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 6
Model: "sequential_7"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_13 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_14 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_7 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7662 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 5.243258237838745
Training Loss per epoch: [0.7662480225723781, 0.7662479777014657, 0.7662480091780759, 0.7662479823894714, 0.7662480004717794, 0.7662479743528902, 0.7662480031506399, 0.7662480145357968, 0.7662480165449421, 0.7662479998020644]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 7
Model: "sequential_8"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_15 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_16 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_8 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7123 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 5.6939520835876465
Training Loss per epoch: [0.7123067144597515, 0.7123067573215185, 0.7123067137900363, 0.7123067224963328, 0.712306735890635, 0.712306747945507, 0.712306747945507, 0.712306741918071, 0.712306754642658, 0.7123067553123731]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 8
Model: "sequential_9"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_17 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_18 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_9 (Dense)              (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6570 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 6.550475835800171
Training Loss per epoch: [0.6569870663492867, 0.656987092468176, 0.65698705630356, 0.656987092468176, 0.6569870770647285, 0.6569870797435889, 0.6569870978258969, 0.6569870449184032, 0.6569870777344435, 0.656987074385868]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 9
Model: "sequential_10"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_19 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_20 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_10 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6590 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 7.666359901428223
Training Loss per epoch: [0.6589756601312188, 0.6589756889289684, 0.6589756949564044, 0.6589756929472591, 0.6589756608009338, 0.6589756674980849, 0.6589756842409626, 0.6589756942866893, 0.6589756842409626, 0.6589756648192245]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 10
Model: "sequential_11"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_21 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_22 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_11 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6699 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 7.9830310344696045
Training Loss per epoch: [0.6698785799272945, 0.6698785859547304, 0.6698786134130499, 0.6698786080553291, 0.6698785906427362, 0.6698785846153003, 0.6698785899730211, 0.6698786000187478, 0.6698785638541318, 0.6698785779181491]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 11
Model: "sequential_12"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_23 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_24 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_12 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7000 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 7.725575923919678
Training Loss per epoch: [0.6999995634796914, 0.6999995219573546, 0.6999995273150755, 0.6999995614705461, 0.6999995695071274, 0.6999995608008309, 0.6999995822317144, 0.699999548745959, 0.6999995387002323, 0.6999995346819416]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 12
Model: "sequential_13"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_25 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_26 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_13 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6087 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 8.341111898422241
Training Loss per epoch: [0.6087399004550462, 0.6087398823727382, 0.6087398549144187, 0.6087398790241627, 0.6087399004550462, 0.6087398341532504, 0.608739881033308, 0.6087398884001742, 0.6087398582629944, 0.6087398582629944]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 13
Model: "sequential_14"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_27 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_28 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_14 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7361 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 9.419977903366089
Training Loss per epoch: [0.7360995579301641, 0.7360995807004779, 0.7360995940947801, 0.7360996034707916, 0.7360995907462045, 0.7360995867279139, 0.7360995612787397, 0.7360995927553499, 0.7360996155256636, 0.7360995867279139]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 14
Model: "sequential_15"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_29 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_30 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_15 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7245 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 9.328397035598755
Training Loss per epoch: [0.7244540486442909, 0.7244540164979656, 0.7244540519928664, 0.724454006452239, 0.7244540298922678, 0.7244540285528376, 0.7244540466351456, 0.7244540272134073, 0.7244540225254016, 0.7244540211859714]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 15
Model: "sequential_16"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_31 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_32 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_16 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6349 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 10.215451955795288
Training Loss per epoch: [0.6348583276352185, 0.634858287452312, 0.6348583108923408, 0.6348582854431667, 0.63485827539744, 0.6348583142409164, 0.6348583269655035, 0.634858317589492, 0.6348583142409164, 0.6348582928100329]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 16
Model: "sequential_17"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_33 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_34 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_17 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7284 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 10.328707933425903
Training Loss per epoch: [0.728421182444926, 0.7284211717294843, 0.7284211723991995, 0.7284211717294843, 0.7284211811054958, 0.728421194499798, 0.7284211844540713, 0.7284212226278326, 0.7284212166003967, 0.7284211623534728]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 17
Model: "sequential_18"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_35 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_36 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_18 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.6584 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration (s) : %s 11.170531988143921
Training Loss per epoch: [0.6584413225731153, 0.6584413540497255, 0.6584413138668189, 0.6584413352977024, 0.658441357398301, 0.6584413118576735, 0.6584413426645687, 0.6584413359674175, 0.658441344673714, 0.6584413312794117]
dict_keys(['loss', 'acc', 'f1_m', 'precision_m', 'recall_m'])
Current iteration: 18
Model: "sequential_19"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
lstm_37 (LSTM)               (None, 5, 50)             11000     
_________________________________________________________________
lstm_38 (LSTM)               (None, 50)                20200     
_________________________________________________________________
dense_19 (Dense)             (None, 1)                 51        
=================================================================
Total params: 31,251
Trainable params: 31,251
Non-trainable params: 0
_________________________________________________________________
Training...
Epoch 1/10
 - 1s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 6/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 7/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 8/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 9/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 10/10
 - 0s - loss: 0.7348 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
