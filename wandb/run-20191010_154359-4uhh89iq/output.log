Preparing training and test sets...
Creating samples using as look_back = 500
--------------------------------------------------
Current iteration: 0
Current number of epochs: 5
Current number of look_backs: 500
Current train size: (144, 501, 4)
Current test size: (141, 501, 4)
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.where in 2.0, which has the same broadcast rule as np.where
Training...
2019-10-10 17:44:04.586702: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
WARNING:tensorflow:From /Users/michele/PycharmProjects/varie/venv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.

Epoch 1/5
 - 2s - loss: 0.5914 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/5
 - 2s - loss: 0.5914 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/5
 - 2s - loss: 0.5914 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/5
 - 2s - loss: 0.5914 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/5
 - 2s - loss: 0.5914 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 9.734525918960571
Training Loss per epoch: [0.5914258625772264, 0.5914258625772264, 0.5914258625772264, 0.5914258625772264, 0.5914258625772264]
--------------------------------------------------
Current iteration: 1
Current number of epochs: 5
Current number of look_backs: 500
Current train size: (144, 501, 4)
Current test size: (141, 501, 4)
Training...
Epoch 1/5
 - 2s - loss: 0.7863 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/5
 - 2s - loss: 0.7863 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/5
 - 2s - loss: 0.7863 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/5
 - 2s - loss: 0.7863 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/5
 - 2s - loss: 0.7863 - acc: 0.0000e+00 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 10.475404739379883
Training Loss per epoch: [0.7862936390770806, 0.7862936390770806, 0.7862936390770806, 0.7862936390770806, 0.7862936390770806]
--------------------------------------------------
Current iteration: 0
Current number of epochs: 5
Current number of look_backs: 500
Current train size: (285, 501, 4)
Current test size: (141, 501, 4)
Training...
Epoch 1/5
 - 4s - loss: 0.6147 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 2/5
 - 3s - loss: 0.6147 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 3/5
 - 3s - loss: 0.6147 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 4/5
 - 3s - loss: 0.6147 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Epoch 5/5
 - 3s - loss: 0.6147 - acc: 1.0000 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00
Training done. Duration: 17.79685091972351
Training Loss per epoch: [0.6146758849160713, 0.6146758849160713, 0.6146758849160713, 0.6146758849160713, 0.6146758849160713]
--------------------------------------------------
Current iteration: 1
Current number of epochs: 5
Current number of look_backs: 500
Current train size: (285, 501, 4)
Current test size: (141, 501, 4)
Training...
Epoch 1/5
